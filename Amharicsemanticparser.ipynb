{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9b9yOCkrwQp"
      },
      "outputs": [],
      "source": [
        "!pip uninstall tensorflow-gpu==2.0.0-alpha0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpR2-S7ivxGp"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.4.1\n",
        "#!pip install tensorflow-gpu==1.14.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwZj6EpPz_X9"
      },
      "outputs": [],
      "source": [
        "!pip3 install --upgrade tensorflow "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSuBEFoR0afT",
        "outputId": "25cef2d5-7fd3-4c71-b05c-d25d582178b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LeIn_c1y8PR",
        "outputId": "53145652-0ffd-48db-dc25-80c1d89404cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvGciB_VDjOz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import string\n",
        "from string import digits\n",
        "import re\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import LSTM, Input, Dense,Embedding, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model,load_model, model_from_json\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.preprocessing.text import one_hot, Tokenizer\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pickle as pkl\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ttj6qMMAH3jh"
      },
      "source": [
        "**import the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4iuIF1hEUk1"
      },
      "outputs": [],
      "source": [
        "with open('/content/unprocessedquestion.txt','r') as f:\n",
        "  data = f.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU3f7AamH7Ma"
      },
      "source": [
        "**Preprocessing Dataset**\n",
        "**1. Data transformation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1u0Ui6ApHt2z"
      },
      "outputs": [],
      "source": [
        "uncleaned_data_list = data.split('\\n')\n",
        "len(uncleaned_data_list)\n",
        "#uncleaned_data_list = uncleaned_data_list[:38695]\n",
        "#len(uncleaned_data_list)\n",
        "Aquestion_word = []\n",
        "logicF_word = []\n",
        "cleaned_data_list = []\n",
        "for word in uncleaned_data_list:\n",
        "  #Aquestion_word.append(word.split('\\t')[:-1][0])\n",
        "  #logicF_word.append(word.split('\\t')[:-1][1])\n",
        "  Aquestion_word.append(word.split('\\t')[0])\n",
        "  logicF_word.append(word.split('\\t')[1])\n",
        "language_data = pd.DataFrame(columns=['question','logicform'])\n",
        "language_data['question'] = Aquestion_word\n",
        "language_data['logicform'] = logicF_word\n",
        "language_data.to_csv('language_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tNAP3PohIVO4",
        "outputId": "4c00ce6f-0c29-4343-c103-a31a4f4099a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-89275a6a-8ac2-42ec-b080-61ed3f374f9e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>logicform</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>አዳማ ከነማ ስፖርት ክለብ በ1932 6ኛ ነው የወጣው</td>\n",
              "      <td>answer ( ? , ደረጃ_1932 ( አዳማ_ከነማ_ክለብ , 6ኛ ) )</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ደደቢት እግርኳስ ክለብ ስፖርት ክለብ በ1960 7ኛ ነው የወጣው</td>\n",
              "      <td>answer ( ? , ደረጃ_1960 ( ደደቢት_እግርኳስ_ክለብ_ክለብ , 7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>የሲዳማ ምስራቃዊ ስፖርት ክለብ ፕሪሚየር ሊግ ይሳተፋል</td>\n",
              "      <td>answer ( ? , ሊግ ( ሲዳማ_ምስራቃዊ_ክለብ , ኢትዮጵያ_ፕሪሚየር_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ከኢትዮጵያ ወንድ እሯጮች በክብደት ትልቁ ማነው</td>\n",
              "      <td>answer ( A , argmax ( ( ሀገር ( A , ኢትዮጵያ ) , ጾታ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>መከላከያ ስፖርት ክለብ በ1989 3ኛ ነው የወጣው</td>\n",
              "      <td>answer ( ? , ደረጃ_1989 ( መከላከያ_ክለብ , 3ኛ ) )</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89275a6a-8ac2-42ec-b080-61ed3f374f9e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-89275a6a-8ac2-42ec-b080-61ed3f374f9e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-89275a6a-8ac2-42ec-b080-61ed3f374f9e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                   question                                          logicform\n",
              "0         አዳማ ከነማ ስፖርት ክለብ በ1932 6ኛ ነው የወጣው       answer ( ? , ደረጃ_1932 ( አዳማ_ከነማ_ክለብ , 6ኛ ) )\n",
              "1  ደደቢት እግርኳስ ክለብ ስፖርት ክለብ በ1960 7ኛ ነው የወጣው  answer ( ? , ደረጃ_1960 ( ደደቢት_እግርኳስ_ክለብ_ክለብ , 7...\n",
              "2        የሲዳማ ምስራቃዊ ስፖርት ክለብ ፕሪሚየር ሊግ ይሳተፋል  answer ( ? , ሊግ ( ሲዳማ_ምስራቃዊ_ክለብ , ኢትዮጵያ_ፕሪሚየር_...\n",
              "3             ከኢትዮጵያ ወንድ እሯጮች በክብደት ትልቁ ማነው  answer ( A , argmax ( ( ሀገር ( A , ኢትዮጵያ ) , ጾታ...\n",
              "4           መከላከያ ስፖርት ክለብ በ1989 3ኛ ነው የወጣው         answer ( ? , ደረጃ_1989 ( መከላከያ_ክለብ , 3ኛ ) )"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "language_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUbbTaWJIXnH",
        "outputId": "cf0c942a-e18f-4991-b128-523744b6c81d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15453, 15453)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "question_text = language_data['question'].values\n",
        "logicf_text = language_data['logicform'].values\n",
        "len(question_text), len(logicf_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K57ATLokKpHa"
      },
      "source": [
        "**2. Data Cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eT-USgqsKTJc"
      },
      "outputs": [],
      "source": [
        "#to lower case\n",
        "question_text_ = [x.lower() for x in question_text]\n",
        "#logicf_text = [x.lower() for x in logicf_text]\n",
        "#removing inverted commas\n",
        "question_text_ = [re.sub(\"'\",'',x) for x in question_text_]\n",
        "#logicf_text = [re.sub(\"'\",'',x) for x in logicf_text]\n",
        "\n",
        "def remove_punc(text_list):\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  removed_punc_text = []\n",
        "  for sent in text_list:\n",
        "    sentance = [w.translate(table) for w in sent.split(' ')]\n",
        "    removed_punc_text.append(' '.join(sentance))\n",
        "  return removed_punc_text\n",
        "\n",
        "question_text_ = remove_punc(question_text_)\n",
        "#logicf_text = remove_punc(logicf_text)\n",
        "remove_digits = str.maketrans('', '', digits)\n",
        "removed_digits_text = []\n",
        "\n",
        "for sent in question_text_:\n",
        "  sentance = [w.translate(remove_digits) for w in sent.split(' ')]\n",
        "  removed_digits_text.append(' '.join(sentance))\n",
        "  \n",
        "question_text_ = removed_digits_text\n",
        "# removing the digits from the marathi sentances\n",
        "#logicf_text = [re.sub(\"[२३०८१५७९४६]\",\"\",x) for x in logicf_text]\n",
        "#logicf_text = [re.sub(\"[\\u200d]\",\"\",x) for x in logicf_text]\n",
        "# removing the stating and ending whitespaces\n",
        "question_text_ = [x.strip() for x in question_text_]\n",
        "#logicf_text = [x.strip() for x in logicf_text]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwhaJ_kVKlqc"
      },
      "source": [
        "**Adding ‘start’ and ‘end’ tag to marathi sentence**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FQpvuKZLcCd",
        "outputId": "b5037ac0-abb1-496d-b350-7578034df579"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('start answer ( ? , ደረጃ_1932 ( አዳማ_ከነማ_ክለብ , 6ኛ ) ) end',\n",
              " 'አዳማ ከነማ ስፖርት ክለብ በ1932 6ኛ ነው የወጣው')"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "# Putting the start and end words in the logic form\n",
        "logicf_text_ = [\"start \" + x + \" end\" for x in logicf_text]\n",
        "question_text_=question_text\n",
        "#marathi_text_ = [\"start \" + x + \" end\" for x in marathi_text_]\n",
        "# manipulated_marathi_text_\n",
        "logicf_text_[0], question_text_[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KjS0kvtMBQ-"
      },
      "source": [
        "**Data preparation for model building**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lf-F8ltDLitH",
        "outputId": "9b22680a-3b3d-49b7-a421-fbac3900d363"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of train example 12362\n",
            "size of test example 3091\n",
            "size of test example የበቀል መንገድ የሚለው ፊልም ላይ አንዷለም ደጀን ተውናለች\n"
          ]
        }
      ],
      "source": [
        "X = question_text_\n",
        "Y = logicf_text_\n",
        "X_train, X_test, y_train, y_test=train_test_split(X,Y,test_size=0.2)\n",
        "print(\"size of train example\",X_train.size)\n",
        "print(\"size of test example\",X_test.size)\n",
        "print(\"size of test example\",X_test[20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwAw2tkiMHvp"
      },
      "source": [
        "Let’s determine the maximum length of our sentences in both English and Marathi:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbClFBAaMJXh",
        "outputId": "2d749fac-e889-4a5a-ce44-eb45b15ed779"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "def Max_length(data):\n",
        "  max_length_ = max([len(x.split(' ')) for x in data])\n",
        "  return max_length_\n",
        "#Training data\n",
        "max_length_english = Max_length(X_train)\n",
        "max_length_marathi = Max_length(y_train)\n",
        "#Test data\n",
        "max_length_english_test = Max_length(X_test)\n",
        "max_length_marathi_test = Max_length(y_test)\n",
        "max_length_marathi, max_length_english"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0ywpU23MNk-"
      },
      "source": [
        "**Tokenization:**\n",
        "As a neural network requires numerical data to process, it becomes necessary to convert our string input to a numerical list. One way of doing this is to use Tokenizer provided by keras-preprocessing library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCr0gJRmMfg-",
        "outputId": "d20888e5-7583-40d4-bb96-1c8487398dcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[402 223   7   1  34  11   4   0   0   0   0   0   0   0]\n"
          ]
        }
      ],
      "source": [
        "englishTokenizer = Tokenizer(filters='#', lower=False)\n",
        "englishTokenizer.fit_on_texts(X_train)\n",
        "Eword2index = englishTokenizer.word_index\n",
        "vocab_size_source = len(Eword2index) + 1\n",
        "\n",
        "X_train = englishTokenizer.texts_to_sequences(X_train)\n",
        "X_train = pad_sequences(X_train, maxlen=max_length_english, padding='post')\n",
        "X_test = englishTokenizer.texts_to_sequences(X_test)\n",
        "X_test = pad_sequences(X_test, maxlen = max_length_english, padding='post')\n",
        "\n",
        "marathiTokenizer = Tokenizer(filters='#', lower=False)\n",
        "marathiTokenizer.fit_on_texts(y_train)\n",
        "Mword2index = marathiTokenizer.word_index\n",
        "vocab_size_target = len(Mword2index) + 1\n",
        "\n",
        "y_train = marathiTokenizer.texts_to_sequences(y_train)\n",
        "y_train = pad_sequences(y_train, maxlen=max_length_marathi, padding='post')\n",
        "y_test = marathiTokenizer.texts_to_sequences(y_test)\n",
        "y_test = pad_sequences(y_test, maxlen = max_length_marathi, padding='post')\n",
        "vocab_size_source, vocab_size_target\n",
        "\n",
        "print(X_train[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgiYTdVaMmod"
      },
      "source": [
        "***To save our preprocessing time*** whenever we reuse it again in future, we will save our important attributes. So, let’s do it first with the help of pickle library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rT6JODvMp43",
        "outputId": "adbcdae8-893c-4c08-c234-36477e21ae21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12362, 14)\n",
            "(12362, 46)\n",
            "(3091, 14)\n",
            "(3091, 46)\n"
          ]
        }
      ],
      "source": [
        "with open('NMT_data.pkl','wb') as f:\n",
        "  pkl.dump([X_train, y_train, X_test, y_test],f)\n",
        "with open('NMT_Etokenizer.pkl','wb') as f:\n",
        "  pkl.dump([vocab_size_source, Eword2index, englishTokenizer], f)\n",
        "with open('NMT_Mtokenizer.pkl', 'wb') as f:\n",
        "  pkl.dump([vocab_size_target, Mword2index, marathiTokenizer], f)\n",
        "X_train = np.array(X_train)\n",
        "print(X_train.shape)\n",
        "y_train = np.array(y_train)\n",
        "print(y_train.shape)\n",
        "X_test = np.array(X_test)\n",
        "print(X_test.shape)\n",
        "y_test = np.array(y_test)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK3tfYwuMxf2"
      },
      "source": [
        "**Model Building**\n",
        "Instead of a simple encoder-decoder architecture, we will be using Attention Mechanism as discussed earlier in this blog.\n",
        "Keras does not officially support attention layer. So, we can either implement our own attention layer or use a third-party implementation. For now, we will be using a third party attention mechanism. This attention is an implementation of ‘***Bahdanau Attention’*** ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAeh1s2TUKtS"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/content/drive/MyDrive/semantic-parser-RNN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5BVagcSAnI4"
      },
      "outputs": [],
      "source": [
        "from attention import AttentionLayer\n",
        "#from keras import backend as K \n",
        "#K.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zi-Dn4ZjM9Gx"
      },
      "outputs": [],
      "source": [
        "latent_dim = 500\n",
        "# Encoder \n",
        "encoder_inputs = Input(shape=(max_length_english,))\n",
        "enc_emb = Embedding(vocab_size_source, latent_dim,trainable=True)(encoder_inputs)\n",
        "#LSTM 1 \n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "#LSTM 2 \n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "#LSTM 3 \n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True) \n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "# Set up the decoder. \n",
        "decoder_inputs = Input(shape=(None,)) \n",
        "dec_emb_layer = Embedding(vocab_size_target, latent_dim,trainable=True) \n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "#LSTM using encoder_states as initial state\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "#Attention Layer\n",
        "attn_layer = AttentionLayer(name='attention_layer') \n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "# Concat attention output and decoder LSTM output \n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "#Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(vocab_size_target, activation='softmax')) \n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
        "plot_model(model, to_file='train_model.png', show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mi4DIbSlNVTd"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWCRCq1PNaA9"
      },
      "source": [
        "**Model Training**\n",
        "We will first define some callbacks so that it would be easy for model visualization and evaluation in future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDHD2GKFNd1j"
      },
      "outputs": [],
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTylXfOrNiN8"
      },
      "source": [
        "**Let's train our Model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxrTX4LENjxt"
      },
      "outputs": [],
      "source": [
        "history = model.fit([X_train, y_train[:,:-1]], y_train.reshape(y_train.shape[0], y_train.shape[1],1)[:,1:], \n",
        "                    epochs=100, \n",
        "                    callbacks=[es],\n",
        "                    batch_size=10,\n",
        "                    validation_data = ([X_test, y_test[:,:-1]], y_test.reshape(y_test.shape[0], y_test.shape[1], 1)[:,1:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3Uq1xLFNo7K"
      },
      "source": [
        "**We can visualize **the loss difference in both training and validation phase as:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Eu3bMEx4NrUw",
        "outputId": "5c85fece-9cf6-43cb-b63d-a97eede45bb8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from matplotlib import pyplot \n",
        "pyplot.plot(history.history['loss'], label='train') \n",
        "pyplot.plot(history.history['val_loss'], label='test') \n",
        "pyplot.legend() \n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caLXRYk8N2Fr"
      },
      "source": [
        "**Model Saving and Loading**\n",
        "Let’s save our trained model with proper weights. Do remember to save the model like I have done as we have to load weights too for the inference model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mIZPad1N6_4",
        "outputId": "da69acc8-c796-4f42-a244-e6528c94676c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk\n"
          ]
        }
      ],
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"NMT_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"NMT_model_weight.h5\")\n",
        "print(\"Saved model to disk\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgGKzhUTN9eK"
      },
      "source": [
        "**Load model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBfKCikOOBQx"
      },
      "outputs": [],
      "source": [
        "# loading the model architecture and asigning the weights\n",
        "json_file = open('NMT_model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "model_loaded = model_from_json(loaded_model_json, custom_objects={'AttentionLayer': AttentionLayer})\n",
        "# load weights into new model\n",
        "model_loaded.load_weights(\"NMT_model_weight.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3edein1kOGo6"
      },
      "source": [
        "**Inference Model**\n",
        "In machine learning we use inference model to predict our output sequences by considering weights from a pre-trained model. In other terms, it can be said that its a model that deduces properties that are learned in training phase and are now used for predicting new sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5G0ubyYOFj5"
      },
      "outputs": [],
      "source": [
        "latent_dim=500\n",
        "# encoder inference\n",
        "encoder_inputs = model_loaded.input[0]  #loading encoder_inputs\n",
        "encoder_outputs, state_h, state_c = model_loaded.layers[6].output #loading encoder_outputs\n",
        "#print(encoder_outputs.shape)\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "# decoder inference\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(14,latent_dim))\n",
        "# Get the embeddings of the decoder sequence\n",
        "decoder_inputs = model_loaded.layers[3].output\n",
        "#print(decoder_inputs.shape)\n",
        "dec_emb_layer = model_loaded.layers[5]\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_lstm = model_loaded.layers[7]\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "#attention inference\n",
        "attn_layer = model_loaded.layers[8]\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "concate = model_loaded.layers[9]\n",
        "decoder_inf_concat = concate([decoder_outputs2, attn_out_inf])\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_dense = model_loaded.layers[10]\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "[decoder_outputs2] + [state_h2, state_c2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLlhhApWO-0M"
      },
      "source": [
        "**Predictions**\n",
        "Now we have trained the sequence to sequence model and created the inference model using the trained model for making a prediction. Let’s predict some Marathi sentences from the English sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8W2xNNcPCcl"
      },
      "outputs": [],
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # Chose the 'start' word as the first word of the target sequence\n",
        "    target_seq[0, 0] = Mword2index['start']\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        if sampled_token_index == 0:\n",
        "          break\n",
        "        else:\n",
        "          sampled_token = Mindex2word[sampled_token_index]\n",
        "        if (sampled_token!='end'):\n",
        "          decoded_sentence += ' '+sampled_token\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'end' or len(decoded_sentence.split()) >= (26-1)):\n",
        "                stop_condition = True\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnrsB228PFAG"
      },
      "source": [
        "**Forming a reverse vocabulary:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA5yIv6jPKBw",
        "outputId": "e29c4f93-7544-402f-a398-fb88c5d146d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{',': 1, '(': 2, ')': 3, 'A': 4, 'start': 5, 'answer': 6, 'end': 7, 'ፊልም': 8, '?': 9, 'count': 10, 'ተዋናይ': 11, 'B': 12, 'ደራሲ': 13, 'ዘፋኝ': 14, 'C': 15, 'ድርሰት': 16, 'አልበም_ስም': 17, 'ይበልጣል': 18, 'የተለቀቀበት_ጊዜ': 19, 'ሰላም_ተስፋየ': 20, 'መጸሃፍ_አይነት': 21, 'ፕሮዳክሽን': 22, 'ዳይሬክተር': 23, 'ሙዚቃ_ስልት': 24, '2009': 25, 'ፕሮድዩሰር': 26, 'ሃኖስ_ፊልም_ፕሮዳክሽን': 27, 'ፊልም_አይነት': 28, 'ሮማንቲክ': 29, 'እውቀቱ_ስዩም': 30, 'የበቀል_መንገድ': 31, '),': 32, 'ካሳሁን_ፍሰሃ': 33, 'ያልተከፈለ': 34, 'ተጨዋች': 35, 'ስብሐት_ገብረእግዚአብሔር': 36, 'መገኛ_ክልል': 37, 'አርዕስት': 38, 'ጃኖ_ባንድ': 39, 'የታተመባት_ጊዜ': 40, 'ጂጂ': 41, 'ሙዚቃ_መሳሪያ': 42, 'ኦርጋን': 43, 'ትርጉም_መጸሃፍ': 44, 'ያስተሰርያል': 45, 'ማሞ_ውድነህ': 46, 'ኅሊና_ደወል': 47, 'የሞተበት_ጊዜ': 48, 'የተወለደበት_ጊዜ': 49, 'በዓሉ_ግርማ': 50, 'ድንግል_ፍቅር': 51, 'እሯጭ': 52, 'ጋዜጠኛ': 53, 'አሜን_ባሻገር': 54, 'ከፍታ': 55, 'ኦሮማይ': 56, 'አልበም_አታሚ': 57, 'አሳታሚ': 58, 'A)': 59, 'የታተመበተ_ጊዜ': 60, 'አሊ_ቢራ': 61, 'ግጥም_መጸሃፍ': 62, 'አለማየሁ_ገላጋይ': 63, 'እህት': 64, 'ዋና_ከተማ': 65, 'ታምራት_ደስታ': 66, 'መገኛ_ቦታ': 67, 'ፉትቦል_ክለብ': 68, 'ኢትዮጵያ': 69, 'መርካቶ_ሰፈሬ': 70, 'ባለቤት': 71, 'አርቲስት': 72, 'ሬጌ': 73, 'አማራ_ክልል': 74, 'ኢትዮ_ጃዝ': 75, 'የተውለድ_ቦታ': 76, 'ዘፈን_የጀመረበት_ቀን': 77, 'ቡድን_ባንድ': 78, 'አብሮ_መስራት': 79, 'ባለሙያ': 80, 'የተወለደበት_ክልል': 81, 'ዋና_ማከፋፋያ': 82, 'ጋምቤላ_ክልል': 83, 'የተሳተፈበት_ሩጫ_አይነት': 84, 'ጾታ': 85, 'ዲግሪ_ያሳበደው': 86, 'ትውልድ_ሀገር': 87, 'ሴት': 88, 'ትውልድ_ቦታ': 89, 'ፍቅር_መጸሃፍ': 90, 'የሚነገር_ቋንቋ': 91, 'ታሪክ_መጸሃፍ': 92, 'ማተሚያ_ቦታ': 93, 'ጨዋታ_ቦታ': 94, 'አጭር_ልብወለድ': 95, 'ቅጽል_ስም': 96, 'እግረ_መንገድ': 97, 'እግርኳስ_ተጨዋች': 98, 'ረጅም_ልብወለድ': 99, 'ተመዘገበ(': 100, 'ዩኔስኮ_አለም_አቀፍ_ቅርስ': 101, 'ገጾች': 102, 'ተመልካች_አቅም': 103, 'ተውኔት_ድርሰት': 104, 'ዋና_አሰልጣኝ': 105, 'ስታድየም': 106, 'ሶማሌ_ክልል': 107, 'አብዱ_ኪያር': 108, 'ኦሮሚያ_ክልል': 109, 'አጥናፍሰገድ': 110, 'ተራራ': 111, 'ትግራይ_ክልል': 112, 'አስቴር_አወቀ': 113, 'ቤንሻንጉል_ጉሙዝ_ክልል': 114, 'ደረጃ_1932': 115, 'ቴዲ_አፍሮ': 116, 'እጅጋየሁ_ሽባባው': 117, 'ምስረታ_ቀን': 118, 'ሀረሪ_ክልል': 119, 'ደቡብ_ብሄሮች_ብሄረሰቦች_ክልል': 120, 'ደረጃ_1935': 121, 'ስራ_አስኪያጅ': 122, 'አፋር_ክልል': 123, 'ጥሩነሽ_ዲባባ': 124, 'ጳውሎስ_ኞኞ': 125, 'ያንሳል': 126, 'ደረጃ_1989': 127, 'እጅጋዬሁ_ዲባባ': 128, 'ደራርቱ_ቱሉ': 129, 'ክልል': 130, 'ቅዱስ_ጊዮርጊስ_ክለብ': 131, 'ሃይሌ_ግርማ': 132, 'ገንዘቤ_ዲባባ': 133, 'ደበበ_ሰይፉ': 134, 'መቐለ_ከነማ_ክለብ': 135, 'ዘሪቱ_ከበደ': 136, 'ሜዳሊያ': 137, 'ሊቀመንበር': 138, 'ሜሮን_ጌትነት': 139, 'አምበል': 140, 'መሰረት_ደፋር': 141, 'ፋሲል_ከነማ_ክለብ': 142, 'ጥልቀት': 143, 'argmin': 144, 'ሀዋሳ_ከተማ_ክለብ': 145, 'ዓለማየሁ_እሸቴ': 146, 'ሳያት_ደምሴ': 147, 'ሀይቅ': 148, 'ኢትዮጵያ_ቡና_ክለብ': 149, 'ድሬዳዋ_ከተማ_ክለብ': 150, 'ደደቢት_እግርኳስ_ክለብ_ክለብ': 151, 'ስፋት(': 152, 'ሙላቱ_አስታጥቄ': 153, 'ኢትዮጵያ_ብሄራዊ_ቡድን': 154, 'እዮብ_መኮነን': 155, 'ህዝብ_ብዛት(': 156, 'አብደላ_እዝራ': 157, 'ሼህ_ሁሴን_ጅብሪል': 158, 'መኮንን_ገ/ዝጊ': 159, 'ተሾመ_ወልዴ': 160, 'ጌታቸው_ካሳ': 161, 'ስፋት': 162, 'ሚሚ_ስብሓቱ': 163, 'ሸዋንዳኘው_ሃይሉ': 164, 'በእውቀቱ_ስዩም': 165, 'ሰላማዊት_ገብሩ': 166, 'ሜሪ_አርምዴ': 167, 'ሻምበል_በላይነህ': 168, 'ትዕግስት_ወይሶ': 169, 'ሀይሉ_ዲሣሣ': 170, 'ሲዳማ_ቡና_ክለብ': 171, 'ፀጋዬ_እሸቱ': 172, 'ግርማ_ነጋሽ': 173, 'አበበ_ቢቂላ': 174, 'ነፃነት_መለሰ': 175, 'እዮኤል_ዮሐንስ': 176, 'አራጋው_በዳሶ': 177, 'ሚካኤል_በላይነህ': 178, 'መዝሙር_ዮሓንስ': 179, 'ኦነሲሞስ_ነሲብ': 180, 'ብርቅርቅታ': 181, 'ሀይሉ_ወርቁ': 182, 'አለማየሁ_ፋንታ': 183, 'ፍስሃ_በላይ_ይማም': 184, 'ጌታመሳይ_አበበ': 185, 'ሀዲስ_ዓለማየሁ': 186, 'ሣኒ_ሐቢብ': 187, 'ተዘራ_ኃይለ_ሚካኤል': 188, 'ጌታቸው_ጋዲሳ': 189, 'ደረጃ_1973': 190, 'ከበደ_ሚካኤል': 191, 'አቦነሽ_አድነው': 192, 'ዳዊት_ጽጌ': 193, 'count(': 194, 'ተስፋዬ_ገሠሠ': 195, 'ሚካያ_በሀይሉ': 196, 'ዮሴፍ_ገብሬ': 197, 'ለማ_ገብረ_ሕይወት': 198, 'የተመዘገበ_ነሀስ': 199, 'ጎሳዬ_ተስፋዬ': 200, 'ቻቺ_ታደሰ': 201, 'በኃይሉ_እሸቴ': 202, 'መራዊ_ዮሓንስ': 203, 'አቢ_ላቀው': 204, 'ህዝብ_ብዛት': 205, 'ኅሩይ_ወልደሥላሴ': 206, 'የዝና_ነጋሽ': 207, 'ተፈራ_ካሣ': 208, 'ቻርለስ_ሳተን': 209, 'ሃይማኖት_ግርማ': 210, 'ጌዲዮን_ዳንኤል': 211, 'ተክለ_ሐዋርያት_ተክለ_ማርያም': 212, 'ማሞ_ወልዴ': 213, 'መንግስቱ_ለማ': 214, 'ተክለጻድቅ_መኩርያ': 215, 'ፍሬው_ኃይሉ': 216, 'ታደሰ_ታምራት': 217, 'የሺጥላ_ኮከብ': 218, 'ራሔል_ዮሓንስ': 219, 'ታሪኩ_በቀለ': 220, 'ተስፋዬ_ገብረአብ_': 221, 'ፀሃፍት': 222, 'ንዋይ_ደበበ': 223, 'አሰፉ_ደባልቄ': 224, 'ደረጃ_1960': 225, 'ታምራት_ሞላ': 226, 'ሲሳይ_ንጉሱ': 227, 'አበባ_ደሳለኝ': 228, 'ፀሐይ_ዮሐንስ': 229, 'ዮሓንስ_ጎዳና': 230, 'ፍቅርአዲስ_ነቃጥበብ': 231, 'ቻላቸው_አሸናፊ': 232, 'እሣቱ_ተሰማ': 233, 'ይስማዕከ_ወርቁ': 234, 'የሽመቤት_ዱባለ': 235, 'መልካሙ_ተበጀ': 236, 'ሳሙኤል_ይርጋ': 237, 'ማርታ_አሻጋሪ': 238, 'አለማየሁ_እሸቴ': 239, 'ኢትዮጵያ_ሴቶች_ብሄራዊ_ቡድን': 240, 'ይርዳው_ጤናው': 241, 'እዮብ_ጌታሁን': 242, 'ሐመልማል_አባተ': 243, 'ሰሎሞን_ተካልኝ': 244, 'ዓለማየሁ_ማሞ': 245, 'አምሳል_ምትኬ': 246, 'ገላን_ተሰማ': 247, 'መኮንን_እንዳልካቸው': 248, 'ፅጌ_ማርያም': 249, 'አበበ_ተሰማ': 250, 'አሰፋ_አባተ': 251, 'ይርጋ_ዱባለ': 252, 'ደረጀ_ደገፋው': 253, 'ኪዳነ_ወልድ_ክፍሌ': 254, 'ብርቱካን_ዱባለ': 255, 'ሽመልስ_አራርሶ': 256, 'ባህሩ_ቀኜ': 257, 'ኃይሉ_ገብረዮሐንስ': 258, 'ማሪቱ_ለገሰ': 259, 'መቅደስ_መስፍን': 260, 'ሚሚ_አዲሱ': 261, 'ገብረሃና_ገብረማሪያም': 262, 'ጭላሎ_ተራራ': 263, 'መከላከያ_ክለብ': 264, 'አሉላ_ዮሐንስ': 265, 'ጌታቸው_አብዲ': 266, 'ትግስት_አፈወርቅ': 267, 'ምኒልክ_ወስናቸው': 268, 'አያልነህ_ሙላቱ': 269, 'ገነት_ማስረሻ': 270, 'ዜናነህ_መኮንን': 271, 'ጥበቡ_ወርቅዬ': 272, 'ገብረክርስቶስ_ደስታ': 273, 'ኬኔዲ_መንገሻ': 274, 'ፀጋዬ_ገብረመድኅን': 275, 'ሀይሌ_ገብረስላሴ': 276, 'አብርሃም_ገብረመድህን': 277, 'ኪሮስ_ዓለማየሁ': 278, 'ኩኩ_ሰብስቤ': 279, 'ተመስገን_ገብሬ': 280, 'ጸጋዬ_ገብረመድህን': 281, 'መላኩ_አሻግሬ': 282, 'ዳኛቸው_ወርቁ': 283, 'ተስፋዬ_አበበ': 284, 'ብሄራዊ_ፓርክ': 285, 'ግርማ_በየነ': 286, 'ጥላሁን_ገሠሠ': 287, 'ማዲንጎ_አፈወርቅ': 288, 'ሐና_ሸንቁጤ': 289, 'ጉጂ_ተራራ': 290, 'ቴወድሮስ_ታደሰ': 291, 'ይሁኔ_በላይ': 292, 'መሀሙድ_አህመድ': 293, 'አረጋኸኝ_ወራሽ': 294, 'አበበች_ደራራ': 295, ',የሚጫወትበት_ቡድን': 296, 'ወልደ_መስቀል': 297, 'አያሌው_መስፍን': 298, 'who': 299, 'ዳዊት_መለሰ': 300, 'ሓጂ_ሙሐመድ': 301, 'አብነት_አጎናፍር': 302, 'አናሲሞስ_ነሲብ': 303, 'ስብሐት_ገብረ_እግዚአብሔር': 304, 'ማናልሞሽ_ዲቦ': 305, 'አስቴር_ከበደ': 306, 'አስናቀች_ወርቁ': 307, 'ስንዱ_ገብሩ': 308, 'አጥናፍሰገድ_ኪዳኔ': 309, 'ደቂቀ_እስጢፋኖስ': 310, 'አበራ_ለማ': 311, 'ወልደ_ቂርቆስ': 312, 'ሽመልስ_በቀለ': 313, 'ሀበነዮም_ሲሳይ_ታረቀኝ': 314, 'አዳም_ረታ': 315, 'ዳምጠው_አየለ': 316, 'ደስታ_ተክለወልድ': 317, 'አባይ_በለጠ': 318, 'ርብቃ_ሰለሞን': 319, 'መስፍን_ሃብተማርያም': 320, 'ጌትነት_ተስፋማርያም': 321, 'አቡ_ሩሚ': 322, 'ዮፍታሄ_ንጉሤ': 323, 'ሰማኸኝ_በለው': 324, 'argmax': 325, '11ኛ': 326, 'ሐይልየ_ታደሰ': 327, 'አበበ_ተካ': 328, 'ሸህ_ጦልሀ_ጀእፈር': 329, 'ጉና_ተራራ': 330, 'በዛወርቅ_አስፋው': 331, 'አዳማ_ከነማ_ክለብ': 332, 'ሳህሌ_ደጋጎ': 333, 'ገብሩ_ደስታ': 334, 'ምስክር': 335, 'ትግስት_ፋንታሁን': 336, 'ወጋየሁ_ደግነቱ': 337, 'ዓለማየሁ_ገላጋይ': 338, 'ጊዜ_ሚዛን': 339, 'ሻሸመኔ_ስምጥ_ሸለቆ': 340, 'አሸናፊ_ከበደ': 341, 'ሙሉቀን_መለሰ': 342, 'አቤ_ጉበኛ': 343, 'ህብስት_ጥሩነህ': 344, 'በታች': 345, 'የተመዘገበ_ብር': 346, 'ሰመመን': 347, 'ብርሃኑ_ዘሪሁን': 348, 'ምዝገባ_ጊዜ': 349, 'ዋንጫ_ብዛት': 350, 'ሂሩት_በቀለ': 351, 'ባህታ_ገብረ_ሕይወት': 352, 'ማህሌት_ደመረ': 353, 'መምህር_ደሴ_ቀለብ': 354, 'ቱሉደሚቱ_ተራራ': 355, 'ጅማ_አባ_ጅፋር_ክለብ': 356, 'አቡዬሜዳ_ተራራ': 357, 'ባህርዳር_ከነማ_ክለብ': 358, 'አቡናዮሴፍ_ተራራ': 359, 'መስፍን_ኃይሌ': 360, 'ዓለማየሁ_ዋሴ': 361, 'ጌታቸው_ኃይሌ': 362, 'አሌክስ_አብርሃም': 363, 'አንኴ_ተራራ': 364, 'አው_ባድር': 365, 'ሀዋሳ': 366, 'ካሣ_ወልዴ': 367, 'ወንድ': 368, 'አሰልጣኝ': 369, 'ቦረና_ሳይንት_ስምጥ_ሸለቆ': 370, '7ኛ': 371, 'ኪዲስያሬድ_ተራራ': 372, 'ታሪካዊ_ቦታ': 373, 'አቤ_ሀይቅ': 374, 'በላይ': 375, 'ዘንገና_ሀይቅ': 376, 'ፍቅር': 377, 'ጎፋ_ዞን_ስምጥ_ሸለቆ': 378, '3': 379, 'አፍሬራ_ሀይቅ': 380, 'ሀገር': 381, 'የተወለዱበት_ክልል': 382, 'ባህር_ወለል_ከፍታ': 383, 'ጫሞ_ሀይቅ': 384, 'ላንጋኖ_ሀይቅ': 385, 'ሀረር': 386, 'መገኛ_ሀገር': 387, 'ራስለስ_ላቀው': 388, 'አሶሳ': 389, 'ደደቢት_እግርኳስ_ክለብ': 390, 'ምስረታ_ጊዜ': 391, 'አባይ_ሀይቅ': 392, 'ንጉሡ_እና_ዘውዱ': 393, '2': 394, 'መቀሌ': 395, 'የህሊና_ደውል': 396, 'የደራሲው_ማሰታወሻ': 397, 'ዳዲ_ቱራ': 398, 'ሎሜ_ሽታ': 399, 'ጊዜ_ዳኛ': 400, 'ያች_ነገር': 401, '3000_ሜትር': 402, 'ለውለታሽ': 403, 'እንግዳ': 404, 'ደበበ_እሸቱ': 405, 'ወደ_ሀገር_ቤት': 406, 'ፓውሎስ_ጌታቸው': 407, 'ኢህአዴግን_እከሳለሁ': 408, 'እውር_አሞራ_ቀላቢ': 409, 'ሶስት_ማእዘን': 410, 'ጌታነህ_ከበደ': 411, 'መልከኞቹ': 412, 'ሚስጥር': 413, 'ስንገናኝ': 414, 'ስንክ_ሳር': 415, 'ሳላስበው': 416, 'ደስ_ሲል': 417, 'አብዮቱ': 418, 'ትምኒት': 419, '6ኛ': 420, 'ጥቁር_አንግዳ': 421, 'የአራዳ_ልጅ': 422, 'ቀዝቃዛው_ጦርነት': 423, 'ላይና_ታች': 424, 'ተራራው_ልቤ': 425, 'ርዝመት(': 426, 'ነጠላ_ዜማ': 427, 'ክፉ_አልምደሽ': 428, 'ውቢቱ_አባተ': 429, 'ፖለቲካ_አይደለም': 430, 'አሳይታ': 431, 'በዙ_ተባዙ': 432, 'የራስ_ጌታ': 433, 'ይሁዳ_ነኝ': 434, 'ውልብታ': 435, 'ያለ_ሴት': 436, 'አጅሬና_አጅሪት': 437, 'የቡርቃ_ዝምታ': 438, 'አልሰጥም': 439, 'ለፍቅር': 440, 'ባንድ': 441, 'በምን_እንግባባ': 442, 'ኩርቢት': 443, 'አስመላሽ': 444, 'ጉድዬ': 445, '7ቱ_ቀናቶች': 446, 'የፍቅር_ሻማዎች': 447, '3ኛ': 448, 'ምንዳ': 449, 'ዘራፍ': 450, 'ያልተኖረ_ልጅነት': 451, 'የልብ_ሽበት': 452, 'መሀከል_ተከላካይ': 453, 'ልክ_እንደሷ': 454, 'ባሳካ_ሀይቅ': 455, 'በጊዜ': 456, 'ጥም_ቆራጭ': 457, 'ሰው_እኮ': 458, 'ፍቅሬን_በአማላጅ': 459, 'ሶስተኛው_አይን': 460, 'ሸማንደፈር': 461, 'አልሞትኹም_ብዬ': 462, 'ጀምበር': 463, 'ጠቋራው_እርግብ': 464, 'የትንቢት_ቀጠሮ': 465, 'ህልመኛው': 466, 'የህዝብ_ጸጸት': 467, 'ሞላ_ጎደል': 468, 'ዳግም_እድል': 469, 'ዘነቡ_ገሰሰ': 470, '1500_ሜትር': 471, 'ጊዜ_ቤት': 472, 'የልቤ_ሰው': 473, 'ለምን': 474, 'የተረት_ሎሚ': 475, 'ለአለም_ማናየ': 476, 'ፈንጅ_ወረዳ': 477, 'የደስታ_ደሴት': 478, 'ሄራን': 479, 'ማርታ_አያሌው': 480, 'መሀል_አጥቂ': 481, 'ገደብ': 482, 'ሁለት_አንድ_ሀገር': 483, 'ሀና': 484, 'ትመጭ_እንደሁ': 485, 'አስረስ_በቀለ': 486, 'የሚተዳደር': 487, 'የመጨረሻዋ_ቀሚስ': 488, 'ሞገድ': 489, 'ቃል_ስጪኝ': 490, 'አልሰዋሽም': 491, 'ግማሽ_ጸሃይ': 492, 'የልብ_ቋንቋ': 493, 'የተዳፈነ': 494, 'ኢትዮጵያ_ፕሪሚየር_ሊግ': 495, 'የፍቅር_ማህተም': 496, 'ስለ_አንች': 497, 'ሲቲ_ቦይ': 498, 'ለልጅ_እዳ': 499, 'ባማካሽ': 500, 'ሰለሞን_ተካ': 501, 'እጸህይወት_አበበ': 502, 'የደንቆሮዎች_ቲያትር': 503, 'የፍልስፍና_አፅናፍ': 504, 'አንድ_እኩል': 505, 'ነጻነት': 506, 'አዲስ_ዓለም': 507, '2013': 508, 'በፍቃዱ_ከበደ_': 509, 'ሁለት_ዱርዬ': 510, 'እንደ_ጸጌረዳ': 511, 'ትግል_ለትዳሬ': 512, 'ሙሽሪት_ሙሽራ': 513, 'አስታራቂ': 514, 'አድስ_ካሳ': 515, 'ጎዳና': 516, 'ያብስራ_ተክሉ': 517, 'የነገርኩሽ_እለት': 518, 'አይራቅ': 519, 'ወለላ_አሰፋ': 520, 'አሻራ': 521, 'ተራሮችን_ያንቀጠቀጠ_ትውልድ': 522, 'እንደ_ቀልድ': 523, 'የአራዳው_ታደሰ': 524, 'አድሱ_ሰው': 525, 'ጋምቤላ_ከተማ': 526, 'ልክ_ነኝ': 527, 'ያላገባው': 528, 'ድል_ለወምዶች': 529, 'ጣና_ሀይቅ': 530, 'አደረች_አራዳ': 531, 'ሚኪያስ_ተስፋየ': 532, 'ጀምበር_አሰፋ': 533, 'ችሮታው_ከልካይ': 534, 'ስቄ_ልሙት': 535, 'ፍሬህይወት_ስዩም': 536, 'ያነገስከኝ': 537, 'ቁማርተኞቹ': 538, 'ኤልያስ_አደፍርስ': 539, 'ተነቃቃን': 540, 'ዳገቱ_ላይ': 541, 'ኤደን_ጌትነት': 542, 'የፍቅር_ጥግ': 543, 'ኤሳያስ_ጅራ': 544, 'አዱኛ': 545, 'ፈለቀ_ካሳ': 546, 'አማካይ': 547, 'ጠባሽ': 548, 'ያልተገራ': 549, 'ያርግልሽ': 550, 'እስክትመጣ': 551, 'አስቴር_በዳኔ': 552, 'ፍቅር_ትቅደም': 553, 'ፍቅሩ_በቀለ': 554, 'ትግስት_ግርማ': 555, 'በትዝታሽ': 556, 'ኤልያስ_አለሙ': 557, 'በእምነት_ሥም': 558, 'በኔ_ዘመን': 559, 'አራቱ_ሻማዎች': 560, 'የትናየት_ታምራት': 561, 'ሄኖክ_ጌቱ': 562, 'ቢኒያም_በቀለ': 563, 'ብርክቲ_አበበ': 564, 'ደረጀ_ሃይሌ': 565, 'እስከዳር_ግርማይ': 566, 'ማህሌት_ሹመት': 567, 'ከጣሪያየ_በታች': 568, 'አማኑኤል_ይልማ': 569, 'ሰለሞን_ተሼ': 570, 'አንተነህ_አስረስ': 571, 'ዦሮ_ጠቢ': 572, 'ባህረን_ከድር': 573, 'ሶስት_መአዘን': 574, '10ኛ': 575, 'ሽልማት': 576, 'ከሴቶቹ_አምባ': 577, 'ባልወስዳት': 578, 'ብርሃኑ_ወርቁ': 579, 'ደም_ለጋሽ': 580, 'የኔ_ሴት': 581, 'ህይወት_በደረጃ': 582, 'ሰላም_ነው': 583, 'ሚስት_ጨርሰናል': 584, 'ልኡል_ሰለሞን': 585, 'በላይነሽ_አመደ': 586, 'አልሰማሽም': 587, 'ፍርያት_የማነ': 588, 'አባቱ_ማነው': 589, 'መለያየት_ሞት_ነው': 590, '4ኛ': 591, 'ሙሃመድ_አህመድ': 592, 'ዓለም_አታላይ': 593, 'ባለስልጣኑ': 594, 'አለማየሁ_ክፍሌ': 595, 'ያማረ_ምላሽ': 596, 'ያልተመለሰው_ባቡር': 597, 'አትውደድ': 598, 'የጌታቸው_ሚስቶች': 599, 'ሰለሞን_ሙሄ': 600, 'ፋሪስ_ብሩ': 601, 'ነጻ_ትገል': 602, 'ፍቃዱ_ከበደ': 603, 'አላበድኩም': 604, 'ስምንተኛው_ጋጋታ': 605, 'ሲስተሪ': 606, 'ራሄል_ይልቃል': 607, 'የልጅ_ሀብታም': 608, 'ከረፈደ': 609, 'ባላደራው': 610, 'ረቂቅ_ተሾመ': 611, 'ፍቅር_አለቃ': 612, 'ሚካኤል_ታምሬ': 613, 'ቢኒያም_አንዳርጌ': 614, 'ምህረት_ማንደፍሮ': 615, 'ይገረም_ደጀኔ': 616, 'እምቢ': 617, 'ማያየ': 618, 'በፍቅር_ስም': 619, 'ረዥም_እርቀት': 620, 'የምሽቱ_ፍፃሜ': 621, 'ሃና_ዮሃንስ': 622, 'ግጥምጥሞሽ': 623, 'ማራቶን': 624, 'አበበ_ወርቁ': 625, 'በእውነት_ስም': 626, 'ተስፋየ_ይማም': 627, 'ሰለሞን_ተስፋየ': 628, 'ሄኖክ_አለማየሁ': 629, 'ልያት_ስዩምም': 630, 'ወራጅ_አለ': 631, 'ማክቤል_ሄኖክ': 632, 'የጠፋው_ልጅ': 633, 'በስህተት': 634, 'አይናለም_ሂርባሳ': 635, 'መልካም_ሴት': 636, 'እቴሜቴ_ሎሚ_ሽታ': 637, 'ልታይ': 638, 'የመልስ_ምት': 639, 'ኤልዛቤት_ጌታቸው': 640, 'ፈልጌ_አስፈልጌ': 641, 'እኛ_የዘጠናዎቹ': 642, 'አልማዝ_ሃይሌ': 643, 'ናርዶስ_አዳነ': 644, 'አንድ_ሀገር': 645, 'እንዳትረሳው': 646, 'ግዛት': 647, 'መስፍን_ጋሻው': 648, 'ቀልድና_ቀለበት': 649, 'ወንዱ': 650, 'ሚኪያስ_ሙሃመድ': 651, 'የተገዘተ': 652, 'ሒሪያ': 653, 'የወፍ_ቋንቋ': 654, 'ቅበላ': 655, 'ማህሌት_ሰለሞን': 656, 'ስለመና': 657, 'አበበ_ባልቻ': 658, 'ማስረሻ_ደጊ_': 659, 'ደስ_የሚል_ስቃይ': 660, 'ሰለሞን_ገብሬ': 661, 'ኢንጀሮቹ': 662, 'ኳራንታይን': 663, 'ሩታ_መንግስትአብ': 664, 'ጅጅጋ': 665, 'ሜሮን_እንግዳ': 666, 'ረድየት_ጌታሁን': 667, 'ረቡኒ': 668, 'ሲሳይ_አብርሀም': 669, 'ሮቤል_ግርማ': 670, 'ማህሌት_ትግስቱ': 671, 'ደርቶጋዳ': 672, 'የኔዎቹ_ገረዶች': 673, 'ማርታ_አሰፋ': 674, 'ሳምሶን_ግርማ': 675, 'ቢንጎ': 676, 'ተፈጣሪ': 677, 'ሳህር_አብዱከሪም': 678, 'ሰብለ_ተፈራ': 679, 'አለማየሁ_በላይነህ': 680, 'ዋሲሁን_በላይ': 681, 'መልካም_ይደግ': 682, 'ህይወት_አበበ': 683, 'ባዩሽ_ከበደ': 684, 'መለሰ_ወልዱ': 685, 'ፋንቱ_ማንዶየ': 686, 'በረከት_በላይነህ': 687, 'ጸጋየ_አበጋዝ': 688, 'እንደ_አባት': 689, 'መለኛው': 690, 'ሜላት_ሰለሞን': 691, 'ልበድላት': 692, 'ደቡብ_ብሄር_ብሄረሰቦች_ክልል': 693, 'እታፈራሁ_መብራቱ': 694, 'ብሩክ_ምናሴ': 695, 'እያዩ_ማዘን': 696, 'ያፈቀረ_አራዳ': 697, 'የጀግና_ልጅ': 698, 'ሰጭ_እና_ተቀባይ': 699, 'መቐለ_ከነማ': 700, 'አደብ_ተራ': 701, 'ሌባና_ፖሊስ': 702, 'አጥፍቶ_ጠፊ': 703, 'ክልል_መንግስት': 704, 'ሰውነቷ': 705, 'ሊግ': 706, '10000_ሜትር': 707, 'ታገቢኛለሽ': 708, 'የቢሾፍቱ_ቆሪጦች': 709, 'አትሞችም': 710, 'ትወደኛለች': 711, 'ታዛ': 712, 'ፋሲል_ከነማ': 713, 'እስክመጭ': 714, 'ትህትና': 715, 'ፌርማታ': 716, 'የነገን_አልወልድም': 717, 'ሙሾ_በከንቱ': 718, 'ፍቅርና_ገንዘብ': 719, 'ባለታክሲው': 720, 'ማርታ_ጌታቸው': 721, 'ፓፓራዚው': 722, 'ዩቶጵያ': 723, 'የቀይ_ኮከብ_ጥሪ': 724, 'ትኩሳት': 725, 'የትምወርቅ_ኑርበዛ': 726, 'ይልነገርኩህ': 727, 'የእናት_ልብ': 728, 'አድስ_ሙሽራ': 729, 'ሰኔ_30': 730, 'ድብልቅልቅ': 731, 'ሳልኳት': 732, 'ይብለጥ_ግዛው': 733, 'የተመዘገበበት_ጉባየ': 734, 'የታሰረ_እውነት': 735, 'ሰጥቶ_መቀበል': 736, 'ያፈቀርኩት_ሰው': 737, 'ያየ_አለ': 738, 'የኡጋደን_ድመቶች': 739, 'ሐዲስ': 740, 'በቁም_ካፈቀርሽኝ': 741, 'ሀይቅ_አይነት': 742, 'ሰበቡ': 743, 'ህያብ': 744, 'ራሃማቶራ': 745, 'ፍቅሩ_አብተ': 746, 'ዋሻው': 747, 'ልክ_እንዳች': 748, 'ዡልየት': 749, 'ስንታየሁ_አረጋ': 750, 'አክቲቪስቱ': 751, 'በመንገዴ': 752, 'ቴወድሮስ_ስዩም': 753, 'ሃይሌ_አስመላሽ': 754, 'ኮከባችን': 755, 'ዊንታና': 756, 'ሲያምረኝ_ተሾመ': 757, 'አለምሰገድ_ተሰፋየ': 758, 'የፍቅር_ኤቢሲዲ': 759, 'እድሜ_ለሴት': 760, 'ማን_አየብኝ': 761, 'ለኔ_ተዉት': 762, 'አርጌው': 763, 'ሼመንደፈር': 764, 'ሃናን_መረሃጽድቅ': 765, 'ካሌብ_አራያስላሴ': 766, 'ላንቺ_ስል': 767, 'ጨዋ_ዱርዬ': 768, 'ጸጋነሽ_ሃይሉ': 769, 'የብርሃን_ፈለጎች': 770, 'የጨዋ_ልጅ': 771, 'ቴወድሮስ_ለገሰ': 772, 'መንግስቱ_ሳሳሞ': 773, 'ጎል_ብዛት': 774, 'ሞኙ_ያራዳ_ልጅ': 775, 'ውለህ_ግባ': 776, 'የሚስቴ_ቀን': 777, 'ባንዳፍ': 778, 'አለሜ': 779, 'በእናት_መንገድ': 780, 'ሰም_አማኑኤል': 781, 'ሙሉአለም_ታደሰ': 782, 'ስዩም_ከበደ': 783, 'የወንዶች_ጉዳይ': 784, 'እድለወርቅ_ጣሰው': 785, 'ሸዋፈራሁ_ደሳለኝ': 786, 'ቁመት': 787, 'ዝነኛዋ': 788, 'ሶልሜት': 789, 'ከእለታት': 790, 'አልደወለም': 791, 'ዘርአይ_ሙሉ': 792, 'ወደ_ገደለው': 793, 'ወርቀ_ዘቦ': 794, 'ውጭ_ጉዳይ': 795, 'ባለቀን': 796, 'የፍቅር_ማስተር': 797, 'ዘረሰናይ_መሃሪ': 798, 'ፍቅሬን_በምን_ቋንቋ': 799, 'የቀለጠው_መንደር': 800, 'ወሬ_ነጋሪ': 801, 'የኔ_ነበር': 802, 'ኤፍሬም_አሻሞ': 803, 'ደረጃ_1998': 804, 'ድፕሎማት': 805, 'እንደ_ባልና_ሚስት': 806, 'ቀይ_ስህተት': 807, 'ግሩም_ቃል': 808, 'ፍጹም_ቃል': 809, 'የሰፈሬ_ልጅ': 810, 'ቶክስዶው': 811, 'አመለሰት_ሙጨ': 812, 'ማርዮስ_ታደለ': 813, 'ባላገሩ': 814, 'ፍዩሪ_ሃይሌ': 815, 'ዳንኤል_ተገኘ': 816, 'የህዝብ_ነኝ': 817, 'አልማዝ_አበበ': 818, 'ትርታይ': 819, 'ሞቅ': 820, 'አቤል_ብርሃኑ': 821, 'ቶማስ_ቶራ': 822, 'ወደፊት': 823, 'እመቤት_ወልደገብርኤል': 824, 'አንቺን_ለኔ': 825, 'ኢሳም_ሀሰን': 826, 'የጓሮ_በር': 827, 'ፍሬው_አበበ': 828, 'ባትጋራኝ': 829, 'ብሩክ_ባህሩ': 830, 'አፋጀሽኝ': 831, 'ሀዋሳ_ከተማ': 832, 'እናፋታለን': 833, 'ታምሩ_ብርሃኑ': 834, 'ብሩክታዊት_ሽመልስ': 835, 'ይሉኝታ': 836, '12ኛ': 837, 'እየሩሳሌም_ገዛሀኝ': 838, 'ባለ_ጊዜ': 839, '5ኛ': 840, 'ሠርክዓዲስ': 841, 'ብሶት_የወለደው': 842, 'ማይጨው': 843, 'የሆድ_አምላኩ_ቅጣት': 844, 'እንዳላጣህ': 845, 'የዳያስፖራ_ፍቅር': 846, 'አቤል_ማሞ': 847, 'ፊት_መስመር': 848, 'በሌን_ማሞ': 849, 'ገዳይ_ሲያረፋፍድ': 850, 'ሀ_እና_ለ': 851, 'ቴና_ገብረሚካኤል': 852, 'ዝናህብዙ_ጸጋየ': 853, 'ደራሲው': 854, 'አዳማ': 855, 'ትርፍ_አንችንም': 856, 'አትሸኟትም_ወይ': 857, 'ጋቶች_ፓኖም': 858, 'ቤዛዊት_መስፍን': 859, 'ከእለታተ': 860, 'ትዛዙ_ታየ': 861, 'ባይታዋር': 862, 'ቅድስት_ገብረስላሴ': 863, 'ከፍሎ_ሟች': 864, 'ዋንጫ_የበላበት_አመት': 865, 'አልዋሽም': 866, 'ወፈፌው_ፍቅር': 867, 'ላትጠቅሚኝ': 868, 'አሸናፊ_ማህሌት': 869, 'ሸፍታው': 870, 'ጸድይ_ፈንታሁን': 871, 'በጨረቃ_ኦቨር': 872, 'ታስጨርሺኛለሽ': 873, 'አንድ_መንገድ': 874, 'ጥቁር_ፈርጥ': 875, 'አዜብ_ወርቁ': 876, 'ሚኪያስ_ስንታየሁ': 877, 'የታወረ_ልብ': 878, 'ፍጹም_አስፋው': 879, 'ሱሴ': 880, 'ሱማሌው_ቫንዳ': 881, 'ወደ_ኋላ': 882, 'ነጻነት_ወርቀነህ': 883, 'ፍናን_ሂድሩ': 884, 'ሳማ': 885, 'ደሳለኝ_ሃይሉ': 886, 'ጆከር': 887, 'ስር_ሚዜው': 888, 'ዳዊት_አባተ': 889, 'ስለ_እውነት': 890, 'ቀን_በቀን': 891, 'ሮማን_አየለ': 892, 'ይስሐቅ': 893, 'ያበድኩለት': 894, 'ቢኒያም_ዱላ': 895, 'ዳግማዊት_ጸሃየ': 896, 'ልዋጭ': 897, 'ዋሲሁን_ተሾመ': 898, 'የምስራች_ግርማ_': 899, 'ቀልድ_አላውቅም': 900, 'ቸርነት_ፍቃዱ': 901, 'እወቁልኝ': 902, 'ጌትነት_አዳነ': 903, 'ስንታየሁ_ክፍሌ': 904, 'ፍሬህይወት_ከልክለው': 905, 'ዮናዳብ_ወርቁ': 906, 'መክሊት_ገብረየስ': 907, 'በንጃሚን': 908, 'ወጣ_ገባ': 909, 'አንፋታም': 910, 'ወይተሩ': 911, 'ቢኒያም_ብርሃኑ': 912, 'ጽጌሬዳ': 913, 'ሌቱም_አይነጋልኝ_': 914, 'ከአድማስ_ባሻገር': 915, 'ዩሃንስ_ተፈራ': 916, 'ባለተራ': 917, 'ሰርቄሽ_ልሂድ': 918, 'ባሌ_ዞን': 919, 'መሀል_ቤት': 920, 'ባለጋሪው': 921, 'ከባድ_ሚዛን': 922, 'የተኛሁ_መስሎሻል': 923, 'ዶክተሩ': 924, 'ገብረመድህን_ሀይሌ': 925, 'ሜሮን_አብረሃ': 926, 'ካሌብ_ዋለልኝ': 927, 'ቦሌ_ማነቂያ': 928, 'ላላገኛት': 929, 'የተጣለ': 930, 'አንችን_ለኔ': 931, 'ዘላለም_ብርሃኑ': 932, 'ግርማ_ታደሰ': 933, 'ባለቀለም_ህልሞች': 934, 'ነበዩ_ኤርሚያስ': 935, 'ሀይቅ_እስጢፋኖስ': 936, 'ማክዳ_አፈወርቅ': 937, 'ማራማዊት_አባተ': 938, 'ቸ_በለው': 939, 'ህይወት_አረጋ': 940, 'ቃልኪዳን_ታምሩ': 941, 'ጌታቸው_እጅጉ': 942, 'አጣምራለች': 943, 'ተአምራዊው_ዋሽንት': 944, 'ፍቅር_መላሽ': 945, 'ቀለምና_ቀሚስ': 946, 'ሙሉአለም_ጌታቸው': 947, 'ዳዊት_ከበደ': 948, 'የድሆች_ከተማ': 949, 'ሰራዊት_ፍቅሬ': 950, 'ያልነገርኩህ': 951, 'ሁለት_ፊርማ': 952, '፩_ጉርሻ': 953, 'ጎሹ_ፍሰሃ': 954, 'ፍቃዱ_ተክለማርያም': 955, 'ቶማስ_በየነ': 956, 'እስከዳር_አባይ': 957, 'ቃልኪዳን_አበራ': 958, 'እሸቱ_አጥናፉ': 959, 'የኔ_ናት': 960, 'በጭስ_ተደብቄ': 961, 'ያረፍኩበት': 962, 'ንጹህ_ሃይሌ': 963, 'ሰቡህ_ጳውሎስ': 964, 'የትም_ተወለድ': 965, 'ላ_ቦረና': 966, 'ጸደንያ_ኤፍሬም': 967, 'አዲሱ_ሰው': 968, 'ባህርዳር_ከነማ': 969, 'ሶንያ_ናኦል': 970, 'ሄኖክ_ድንቁ': 971, 'እኔ_ማን_ነኝ': 972, 'ሊዲያ_ጥበቡ': 973, 'ሰብስቤ_ፈቀደ': 974, '100_ይቅርታ': 975, 'ተውልኝ': 976, 'ከልክ_በላይ': 977, 'ኤፍሬም_ታደሰ': 978, 'ሰይፍ_አራያ': 979, 'ተስፉ_ብርሃኔ': 980, 'የኛ_ልጅ_በርታ_በርታ': 981, 'አለማየሁ_ደረሰ': 982, 'ቴወድሮስ_ስፍራየ': 983, 'የፈጣሪ_ጊዜ': 984, 'አሜኬላ': 985, 'ሰባ_ዘጠኝ': 986, 'ውሳኔ_2': 987, 'ሙሃመድ_ሚፍታ': 988, 'ኤዶሚያስ': 989, 'ታምራት_ሃይለጊውርጊስ': 990, 'ኤደን_ሽመልስ': 991, 'እሷን_ብየ': 992, 'ቃልኪዳን_ጥበቡ': 993, 'መግደል_መሸነፍ': 994, 'ጽኑ_ቃል': 995, 'የመጀመሪያዬ': 996, 'ነብዩ_እንድሪስ': 997, 'እፍታ': 998, 'መታሰቢያ_ታደሰ': 999, 'ኪያ': 1000, 'ሳሮን_አየልኝ': 1001, '_ሰለሞን_ቦጋለ': 1002, 'ሁለት_ባል': 1003, 'ስወደህ': 1004, 'መላክ': 1005, 'ምንሼ': 1006, 'የራስ_እውነት': 1007, 'ፈልግሻለሁ': 1008, 'ያደራ_ልጅ': 1009, 'ፍቅር_በኩረጃ': 1010, 'ጥቅም_ያለበት_ጨዋታ': 1011, 'ወይንሸት_አበጀ': 1012, 'መስሎኝ': 1013, 'ሃምዛ_አለሙ': 1014, 'ታሪኩ_ብርሃኑ': 1015, 'ጉራ_ብቻ': 1016, 'የአዲስ_አበባ_ሃብታም': 1017, 'ሸዊት_ከበደ': 1018, 'ባንች_ጊዜ': 1019, 'ብርሃኔ_ገብሩ': 1020, 'ፍቅር_አዳኝ': 1021, 'ፈላሻው': 1022, 'የሰው_ወርቅ': 1023, 'ያገር_ሌባ': 1024, 'ተዘራ_ለማ': 1025, 'ሽመልስ_አበራ': 1026, 'ሰምሃል_ጥላሁን': 1027, 'ገናዡ': 1028, 'ጸድይ_መስፍን': 1029, 'ዮናስ_ጌታቸው': 1030, 'ያይኔ_አበባ': 1031, 'ከደመና_በላይ': 1032, 'ንግስት_ፍቅሬ': 1033, 'ቆዳ_ስፋት(': 1034, 'አስቴር_አለማየሁ': 1035, 'አብነት_ዳግም': 1036, 'ዊንታ_ታደሰ': 1037, 'ገሊላ_ረሶም': 1038, 'ሃናን_ታሪክ': 1039, 'ምስጋና_አጥናፉ': 1040, 'ፈርሙለኝ': 1041, 'ኤርሚያስ_ታደሰ': 1042, 'ሲዳማ_ቡና': 1043, 'ደባል': 1044, 'ከእለታተ_ግማሽ_ቀን': 1045, 'ባጣ_ቆዩኝ': 1046, 'ኤልያስ_ወሰንየለህ': 1047, 'ጌታሁን_ታደሰ': 1048, 'አንቸሆየ': 1049, 'ግሩም_ኤርሚያስ': 1050, 'ድሬዳዋ_ከተማ': 1051, 'ሞተረኛው': 1052, 'ክላስሜት': 1053, 'ብሩክ_ይበልጣል': 1054, 'የራስ_ጥላ': 1055, 'መስፍን_ሃይለኢየሱስ': 1056, 'እንደዚህ_እንደዛ': 1057, 'ሰራችልኝ': 1058, 'ወይንሸት_በላቸው': 1059, 'አጥቢያ': 1060, 'ግንባታ_ቀን': 1061, 'ባለቀሚስ': 1062, 'ኪሮስ_ሃይለስላሴ': 1063, 'አድሳለም_ጌታነህ': 1064, 'አዳማ_ከነማ': 1065, 'አላረጅም': 1066, 'ደረጀ_ደመቀ': 1067, 'ማስተዋል_ወንደሰን': 1068, 'ላስታውስሽ': 1069, 'የእጄን': 1070, 'ማዕበል': 1071, 'ሀረር_ጀጎል': 1072, 'ሚካኤል_ሚሊዮን': 1073, 'ብቸኛው': 1074, 'ዘላለም_ይታገሱ': 1075, 'ፕሬዝዳንት': 1076, 'የሰው_ሰው': 1077, 'ሽፈራው_ተክለማሪያም': 1078, 'የትንሳኤ_ወጥመድ': 1079, 'ሞገስ_ቸኮለ': 1080, 'ፋንታ_ስንታየሁ': 1081, 'ኮንሶ_ምድር_ስእል': 1082, 'ቢኒያም_አማን': 1083, 'ናሆም_ጌታቸው': 1084, 'ሉሊት_ገረመው': 1085, 'አቶና_ወይዘሮ': 1086, 'የትዳር_ያለህ': 1087, 'እመጓ': 1088, 'ደመወዝ_ጎሸሜ': 1089, 'አርሴማ_ወርቁ': 1090, 'ዮሴፍ__ፍቀደ': 1091, 'በህግ_አምላክ': 1092, 'ስሞን_ጸጋየ': 1093, 'ሸንተረር': 1094, 'ተለዋዋጭ': 1095, 'ዘናጭ': 1096, 'ማክዳ_ሃይሌ': 1097, 'ንጹህ_ውሀ_ሀይቅ': 1098, 'ያልጠባ_መስከረም': 1099, 'መሻት': 1100, 'የኢትዮጵያ_ተጠሪ_ማነው': 1101, 'መሳይ_ግርማ': 1102, 'ከታያት': 1103, 'ሔሮሺማ': 1104, 'አልተመቻቸንም': 1105, 'እንዳይወጣ': 1106, 'ቃል_ስጭኝ': 1107, 'አክሱም': 1108, 'ሊነጋ_ሲል': 1109, 'የቅርብ_እሩቅ': 1110, 'ፍርያት_በርሂ': 1111, 'ቤቴል_ተስፋየ': 1112, 'የኋላሸት_በለጠ': 1113, 'ሀረርጌ_ዞን': 1114, 'የናፈኩት_ሲቀር': 1115, 'ገነት_ንጋቱ': 1116, 'የሴት_ፍቅር': 1117, 'ፍቅር_የት_አለሽ': 1118, 'ህይወት_ጌታሁን': 1119, 'ሰሜን_ጎንደር': 1120, 'ዳንኤል_ገነየሁ': 1121, '1ኛ': 1122, 'ቀና_በይ': 1123, 'ለኔ': 1124, 'ቦንቡ_ፍቅር': 1125, 'እዮሪካ': 1126, 'ሜላት_ነብዩ': 1127, 'ሰገን_ይፍጠር': 1128, 'ወዶ_ገዳይ': 1129, 'አድስ_አበባ_ስታድየም': 1130, 'ዳንኤል_ታየ': 1131, 'ኦሞ_ስምጥ_ሸለቆ': 1132, 'ጥሎ_ማለፍ': 1133, 'ኤማንዳ': 1134, 'አሳሳች': 1135, 'ዛክ_ግዛው': 1136, 'ወቶ_አደር': 1137, 'ውስጣችን': 1138, '8ኛ': 1139, 'ታላቅና_ታናሽ': 1140, 'ፌቨን_ከተማ': 1141, 'የተቆለፈበት': 1142, 'ቴወድሮስ_ክፍሌ': 1143, 'መሳይ_ጌታሁን': 1144, 'ድርብወርቅ_ሰይፉ': 1145, 'ያሬድ_ኢጉ': 1146, 'ሰብስቤ_ዘርጋው': 1147, 'ይመችሽ_ያራዳ_ልጅ': 1148, 'የጋዜጠኛው_ማስታወሻ': 1149, 'ዳንኤል_አበበ': 1150, 'ኮንዶሚኒየሙ': 1151, 'የት_ነበርሽ': 1152, 'የአርበኛው_ልጅ': 1153, 'ልዩ_ሰው': 1154, 'ፋሲል_ግቢ': 1155, 'አርሲ_ዞን': 1156, 'አስራት_ታደሰ': 1157, 'አልማዜ': 1158, 'ሰባ_ደረጃ': 1159, 'ፀሐይ_መስፍን': 1160, 'ምትኬ': 1161, 'አንድ_ሙሽራ': 1162, 'ማንደፍሮ': 1163, 'ማን_ያግባት': 1164, 'አርሴማ_አባይነህ': 1165, 'ላገባ_ስል': 1166, 'አዋሽ_ስምጥ_ሸለቆ': 1167, 'አማን': 1168, 'አብይ_ገብረማሪያም': 1169, 'የመጨረሻው_መጀመሪያ': 1170, 'ሮማን_አባተ': 1171, 'ሳቅልኝ': 1172, 'ሮማን_በፍቃጉ': 1173, 'ጎበዝ_አየን': 1174, 'የሰው_ያለህ': 1175, 'ፍሬ': 1176, 'ስረሳሽ_አስታውሽኝ': 1177, 'እርሳኝ': 1178, 'ሜላት_ይርጋለም': 1179, 'የፈሪ_ጀግና': 1180, 'ሲሳይ_ነው': 1181, 'ባንች_የመጣ': 1182, 'ኡመድ_ኡክሪ': 1183, 'በዝምታ': 1184, 'መውጫ_የለም': 1185, 'መንሱት': 1186, 'መጣ_በፈረስ': 1187, 'አንዷለም_ደጀን': 1188, 'ደምስ_በየነ': 1189, 'አንድ_ቀን': 1190, 'ባትመጪስ': 1191, 'ዮሴፍ_ዳንኤል': 1192, 'የሐምሌ_ሙሽራ': 1193, 'ቢንያም_ደምጤ': 1194, 'የትሮይ_ፈረስ': 1195, 'ጨዋወቹ': 1196, 'ሄሎ': 1197, 'ፍጹም_ጸጋየ': 1198, 'ሸማመተው': 1199, 'አንድ_ለአባቷ': 1200, 'ልዩ_ናት': 1201, 'ሚስጥሩ': 1202, 'ሰሜን_ወሎ': 1203, 'ጎል_አግቢ': 1204, 'የማላውቀው': 1205, 'ረጅም_ልብወለድ_መጸሃፍ': 1206, 'ሰይፈሚካኤል_ተስፋየ': 1207, 'ተከፍሏል': 1208, 'ንግስተ_ሳባ': 1209, 'ወርልድ_ሪከርድ': 1210, 'ካለሽ_አለሁ': 1211, 'አማኑኤል_ሀበታሙ': 1212, 'ለፀብ_ያረገዘች': 1213, 'ዮናስ_አሰፋ': 1214, 'ብዙአየሁ_አለሙ': 1215, 'ምህረት_በለጠ': 1216, 'ልምምድ_ስታድየም': 1217, 'ከአፍ_ሲያመልጥ': 1218, 'ህሌና_ሲሳይ': 1219, 'ቴወድሮስ_ጋሻውበዛ': 1220, 'ቴወድሮስ_ተሾመ': 1221, 'ሰአሊ': 1222, 'ስእል_ስራ': 1223, 'ሳሙኤል_ጥላሁን': 1224, 'ተሾመ_ቋንኩሴ': 1225, 'እምነት': 1226, 'እርሜን_ብዝናና': 1227, 'ያከበርኩት': 1228, 'ሳቅ_እና_ለቅሶ': 1229, 'የስደተኛው_ማስታወሻ': 1230, 'ኢትዮጵያ_ደጋ': 1231, 'ጌታሁን_ሰለሞን': 1232, 'ከፍቅር_በላይ': 1233, 'እጅ_ወደ_ላይ': 1234, 'ስንቴ_ልሙትልሽ': 1235, 'ካንች_በላይ': 1236, 'ናታይ_ጌታቸው': 1237, 'ሀገር_ስጭኝ': 1238, 'ጠባሹ': 1239, 'የዳስቦራ_ፍቅር': 1240, 'ህጋዊ_ጋብቻ': 1241, 'ስናፍቅሽ_ተስፋየ': 1242, 'ነበያት_መኮነን': 1243, 'አብራር_አብዶ': 1244, 'እርቅ_ይሁን': 1245, 'መከላከያ': 1246, 'ቅኝት': 1247, 'የሚጫወቱት_ቅኝት': 1248, 'ብርቱካን_በፍቃዱ': 1249, 'ላንተ_ስል': 1250, 'ትዳሪን_ተበላሁ': 1251, 'ባንች_መንገድ': 1252, 'ማርሽ_ቀያሬው': 1253, 'መቀደስ_ጸጋየ': 1254, 'ጃዕፈር_መጸሃፍ_መደብር': 1255, 'ፍቅርተ_ጌታሁን': 1256, 'ሜሮን_ተሾመ': 1257, 'አብርሃም_ጸጋየ_': 1258, 'ድፍረት': 1259, 'አዜብ_ወንደሰን': 1260, 'ተስፋየ_ገሰሰ': 1261, 'ውሃና_ወርቅ': 1262, 'ወንደሰን_ብርሃኑ': 1263, 'ኤፍሬም_ሙላት': 1264, '7ኛው_መልአክ': 1265, 'ዳዊት_ፍቃዱ': 1266, 'ወንደሰን_አውራሪስ': 1267, 'አንድሪያስ_አስናቀው': 1268, 'አብርሃም_ያለው': 1269, 'ሰላም_አሻግሬ': 1270, 'ያምራል_ሀገሬ': 1271, 'እንቁስላሴ_ወርቅአገኘሁ': 1272, 'ግልባጭ': 1273, 'ጌትነት_ፈይሳ': 1274, 'አጭር_ልብወለድ_መጸሃፍ': 1275, 'እጥፍወርቅ_ወንዳፈራሽ': 1276, 'ዝጓራ': 1277, 'ስደት': 1278, 'ማህሌት_ፍቃዱ': 1279, 'ሰማያዊ': 1280, 'አውንጅ': 1281, 'ሃረገወይን_አሰፋ': 1282, 'ሞሪያም_ምድር': 1283, 'ቅኔው': 1284, 'ያልተከፈለ__ክብር': 1285, 'ሚስታችን': 1286, 'ፍቅሬን_ላድን': 1287, 'ወንድም': 1288, 'ጸጋየ_ዘርፉ': 1289, 'ቴወድሮስ_ፍቃዱ': 1290, 'ተሻለ_ወርቁ': 1291, 'እንሳሮ': 1292, 'ማልዳ': 1293, 'ሀገር_ስጪኝ': 1294, 'ራሄል_ግርማ': 1295, 'ሄኖክ_ብርሃኑ': 1296, 'ኡመር_እንድሬስ': 1297, 'ክስተት': 1298, 'ማህደር_አሰፋ': 1299, 'የእግዚር_ድልድይ': 1300, 'እናሲዝ': 1301, 'ያቤፅ': 1302, '3ተኛው_ዓይን': 1303, 'ፍቅር_አለ': 1304, 'ስለእናት_ልጅ': 1305, 'የኅሊና_ደወል': 1306, 'የፍቅር_መልስ': 1307, 'ጥያ_ቅርስ_ቁፋሮ_ቦታ': 1308, 'ዳዊት_ስንታየሁ': 1309, 'አቋራጭ': 1310, 'ማቲያስ_ባዩ': 1311, 'ፍሬህይወት_መለሰ': 1312, 'ኤልያስ_ሻፊ': 1313, 'ማስታወሻ': 1314, 'ተውኔት_መጸሃፍ': 1315, 'አብርሃም_ቀናው': 1316, 'ታከቅ_ነጋሽ': 1317, 'ዋሊድ_አታ': 1318, 'አሰፋ_ገብረሚካኤል': 1319, 'ላምባድና': 1320, 'ተስፋአለም_ታምራት': 1321, 'መኮነን_ላአከ': 1322, 'ፍቅርተ_ደሳለኝ': 1323, 'በመንገዴ_ላይ': 1324, 'ፈውሲ_ልቢ': 1325, 'ዳንኤል_ታደሰ': 1326, 'ሰላም_ዘርአይ': 1327, 'ደቡብ_ጎንደር': 1328, 'ፍቅር_ምናገባው': 1329, 'መስከረም_አበራ': 1330, 'የብቻየ': 1331, 'ቀነኒሳ_በቀለ': 1332, 'ባለ_ቀን': 1333, 'ማርካ': 1334, 'ብሩክ_ታምሩ': 1335, 'ክብደት': 1336, 'ቆዳ_ስፋት': 1337, 'አብርሀም_ሀይማኖት': 1338, 'ጋንታ': 1339, 'ያለ_ባል': 1340, 'ላሊበላ_ውቅር_አብያተ_ክርስቲያናት': 1341, 'ማርታ_አባይ': 1342, 'ኢ_ልብወለድ_መጸሃፍ': 1343, 'የታገተ_ፍቅር': 1344, 'መራኝ': 1345, 'ቻንስ_ነው': 1346, 'ወንዝ': 1347, 'ወደ_ውስጥ_የሚፈሱ': 1348, 'ፍልስፍና_መጸሃፍ': 1349, 'ቢኒያም_ወርቁ': 1350, 'ሮክ': 1351, 'እዮብ_ዳዊት': 1352, 'ጨዋ': 1353, 'የፍቅር_መንገድ': 1354, 'ብራዘርሊ': 1355, 'እወድሃለሁ': 1356, 'የሩጫየ_ሩጫ': 1357, '5000_ሜትር': 1358, 'ምስረታ_ቦታ': 1359, 'ህሌና_ጌታቸው': 1360, 'ስሜን_ብሄራዊ_ፓርክ': 1361, 'ኢትዮጵያ_ቡና': 1362, 'አርግዛለሁ': 1363, 'እናት_ናት': 1364, 'ተመስገን_መላኩ': 1365, 'አለባቸው_መኮነን': 1366, 'እንግዳሰው_ሃብቴ': 1367, 'ግማሽ_ማራቶን': 1368, 'መንገደኛው': 1369, 'ወሪሳ': 1370, 'የአዳም_ገመና': 1371, 'ሽናሻ': 1372, 'ዘሪሁን_አስማማው': 1373, 'ዮናስ_ብርሃኔ': 1374, 'አትውለድ': 1375, 'ነጻነት_አይተንፍሱ': 1376, 'ያብስራ_ጌታቸው': 1377, 'ተረትና_ምሳሌ_መጸሃፍ': 1378, 'ጉድፍቻ': 1379, 'አይነጋም_ወይ': 1380, 'የራሄል_መንገድ': 1381, 'ማህደር_ሹመት': 1382, 'ተረት_ሆኖ_ቀረ': 1383, 'ለመኖር': 1384, 'ማን_አየሁ': 1385, 'አርፋጅ': 1386, 'ጅማ_አባ_ጅፋር': 1387, 'አህመድ_ኑሩ': 1388, 'ኤርሚያስ_ወልደአምላክ': 1389, 'በላይ_ጸጋየ': 1390, 'ሀደኛ': 1391, 'ፍቅር_እንዳበደ': 1392, 'ከአቅሜ_በላይ_ነው': 1393, 'ጉሙዝኛ': 1394, 'ቅዱስ_ጊዮርጊስ': 1395, 'ምትኩ_ፈንቴ': 1396, 'ቅድስት_ባየልኝ': 1397, 'ስኳር': 1398, 'ቤንሻንጉል_ጉሙዝ': 1399, 'ሱራፌል_ተካ': 1400, 'ድሬዳዋ_ስታድየም': 1401, '1935': 1402, '17ኛ': 1403, 'ሻኪር_አህመድ': 1404, 'እንዳንቺ_ቃል': 1405, 'ሶማሌኛ': 1406, 'ሹመት_ይድነቃቸው': 1407, 'ሄርሞን_ሃይላይ': 1408, 'ምስራቅ': 1409, 'ቴዎድሮስና_ጣይቱ_ብጡል': 1410, 'ሲዳማ_አጺውቹ_ክለብ': 1411, 'መሰረት_መብራቴ': 1412, 'ቤቴል_መንግስቴ': 1413, '14ኛ': 1414, 'በርታ': 1415, 'ሳይኮሎጅ_መጸሃፍ': 1416, 'የማነ_ደምሴ': 1417, 'ስዩም_ተስፋየ': 1418, 'መስፍን_ጌታቸው': 1419, 'የተመዘገበ_ወርቅ': 1420, 'ሳይንስ_መጸሃፍ': 1421, 'አይዳ_ሙሉነህ': 1422, '112ኛ': 1423, 'አዋሽ_ወረዳ_ምድር_ስእል': 1424, 'የልብ_ጌጥ': 1425, 'ዳዊት_ሽመልስ': 1426, 'ወሪያ': 1427, 'ስታድየም_አይነት': 1428, 'ሳር': 1429, 'አዳነች_አድማሱ': 1430, 'ማርታ_ጎይቶም': 1431, 'ፖለቲካ_መጸሃፍ': 1432, 'ወሳኝነህ_ሃይሉ': 1433, 'ሀረሪኛ': 1434, 'ነገር_በደላላ': 1435, 'አበበ_ቢቂላ_ስታድየም': 1436, 'የሚጫወትበት_ቡድን': 1437, 'ጥቁር_ሰው': 1438, 'ሜሮን_ህሩይ': 1439, '110ኛ': 1440, 'አበበ_ተምትም': 1441, 'ጀማል_ጣሰው': 1442, 'ቦረናሳይንት_ብሄራዊ_ፓርክ': 1443, 'ስዩም_ተፈራ': 1444, 'በላይ_ጌታነህ': 1445, 'ሌላ_ቀን': 1446, 'ሚካኤል_ዎግህ': 1447, 'ያደላል': 1448, 'ሉሲ_ገብረግዚአብሔር': 1449, 'አብነት_አየለ_': 1450, 'ዘረሰናይ_ብርሃኔ': 1451, 'ሃገሬ': 1452, 'ሞገስ_ታፈሰ': 1453, 'ማን_ከማን': 1454, 'ሄኖክ_ወንድሙ': 1455, 'ሰላም_መኩሪያ': 1456, 'ኦሞ_ዞን_ምድር_ስእል': 1457, 'አንድ_ሁለት': 1458, 'ዘላለም_ወልደማርያም': 1459, 'ግሩም_ዘነበ': 1460, 'ባህርዳር_ስታድየም': 1461, 'ሳምራዊት_ሰይድ': 1462, 'ሳቂልኝ': 1463, 'አሰግድ_ግብረእግዚአብሄር': 1464, 'አጥቂ': 1465, 'አፍ_መክፈቻ_ቋንቋ': 1466, 'ካፌቶ_ሽራሮ_ብሄራዊ_ፓርክ': 1467, 'ሚሊዮን_ብርሃኔ': 1468, 'አዚዛ_አህመድም': 1469, 'ጉራጌኛ': 1470, 'ይድነቃቸው_ተሰማ': 1471, '13ኛ': 1472, '2ኛ': 1473, '2010': 1474, 'ምስራቃዊ': 1475, 'ፈለቀ_አበበ': 1476, 'አዳማ_ስታድየም': 1477, 'ፀጋው_ታደሰ': 1478, '16ኛ': 1479, 'ደምሳቸው_ፈንታ': 1480, 'ቀኝ_ተከላካይ': 1481, 'ቡናና_ባለቤቶቹ': 1482, 'ቶሩ': 1483, 'ሀይለማርያም_ሰገዎቃል': 1484, 'ሰማኝገታ_አይችሉህም': 1485, '1932': 1486, 'ባሌ_ብሄራዊ_ፓርክ': 1487, 'ኦሮምያ_ክልል,': 1488, 'ኮሎኒል_ዳኒኤል_ቡሳ': 1489, 'አብርሀም_መብራቱ': 1490, 'ፍሬህይወት_ባህሩ': 1491, '2003': 1492, 'አልጋነሽ_ታሪኩ': 1493, 'ጸጋየ_ብርሃኔ': 1494, '111ኛ': 1495, 'አበረረኝ': 1496, 'በረከት_ወረደ': 1497, 'ሳምሶን_ጊወርጊስ': 1498, '2005': 1499, 'የትናየት_ባህሩ': 1500, 'ቤተልሄም_ከፍያለው': 1501, 'ሕይወት_አድማሱ': 1502, 'ሚኪያስ_ተካ': 1503, 'ሶል': 1504, 'አፋርኛ': 1505, 'አብጃታ_ብሄራዊ_ፓርክ': 1506, 'ቲወድሮስ_ተሾመ': 1507, 'ሌላ_ስም': 1508, 'ደጋጋ_ወልዴ': 1509, 'ሳምሶን_ታደሰ': 1510, 'ነጭሳር_ብሄራዊ_ፓርክ': 1511, 'ወልድያ_ስታድየም': 1512, 'ፖፕ_ሮክ': 1513, 'ቤዝ_ጊታር': 1514, 'አንችሆየ': 1515, 'ዘፈኖች': 1516, 'ያሬድ_ዘለቀ': 1517, 'ሲዳማ_የጣና_ሞገዶቹ_ክለብ': 1518, 'አልማዝ_አያና': 1519, 'ጋምቤላ_ብሄራዊ_ፓርክ': 1520, 'ነጻነት_ተሻገር': 1521, 'ጠቅላይ_ሚኒስተር': 1522, 'ደረጀ_መርሻ': 1523, 'ኦሞ_ብሄራዊ_ፓርክ': 1524, 'በሀይሉ_ማሞ': 1525, 'ጅማ_አባ_ጅፋር_እግርኳስ_ክለብ': 1526, 'ባቲ': 1527, 'ይድነቃቸው_ሹመቴ': 1528, 'ፍቅር_በአማርኛ': 1529, 'መቻል': 1530, '1989': 1531, 'ራፕ': 1532, 'ዮናስ_ሰለሞን': 1533, 'ትውልድ_ቀን': 1534, 'ጋዜጠኝነትን_የጀመረበት': 1535, 'ዳዊት_ላቀው': 1536, '2011': 1537, 'ሉሲ': 1538, 'አፍሮ_ቢት': 1539, 'ጸጋየ_ዩሃንስ': 1540, 'አትነካኩኝ': 1541, 'ሮሃ_ሙዚቃ_ባንድ': 1542, 'ሲዳማ_ሰማያወቹ_ክለብ': 1543, 'አዋሳ_ከነማ_ስታድየም': 1544, 'በላየ_ጌታነህ': 1545, 'ቅኔ_ሙዚቃ_ባንድ': 1546, '15ኛ': 1547, 'ልለይ_ደመወዝ': 1548, 'አንባሰል': 1549, 'ፖፕ': 1550, 'ሰለሞን_በቀለ': 1551, 'ትዝታ': 1552, 'ላንጋኖ_ሀይቅ,': 1553, 'ሀይፐር_ፊልም_ፕሮዳክሽን': 1554, 'ዮዲት_መንግስቱ': 1555, 'ሃሁ_ፕሮዳክሽን': 1556, 'ባህሌን': 1557, 'በቆጅ': 1558, 'አቤ_ሀይቅ,': 1559, '2007': 1560, 'ሰለሞን_አለሙ': 1561, 'አዲስ_አበባ': 1562, 'የጣና_ሞገዶቹ': 1563, 'አክሱም_ፒክቸር': 1564, 'ማጎ_ብሄራዊ_ፓርክ': 1565, 'ፓፓ_ፊልም_ፕሮዳክሽን': 1566, 'ትርጉም': 1567, 'ፎንተኒና_ፊልም_ፕሮዳክሽን': 1568, 'ታሪኩ_በቀለ_ስታድየም': 1569, 'ዋግ_ኮምኒኬሽን_ኢንተርፕራይዝ': 1570, 'ሰማያወቹ': 1571, '2008': 1572, 'ሀይሌ_አድስ_ፒክቸር': 1573, 'ትግራይ_ስታድየም': 1574, 'ቅዱስ_ጊዮርጊስ_እግርኳስ_ክለብ': 1575, 'አባል': 1576, 'ማዜ_ብሄራዊ_ፓርክ': 1577, 'ተረትና_ምሳሌ': 1578, 'ሳይንስ': 1579, 'ሰርክአድስ_ፊልም_ፕሮዳክሽን': 1580, 'ኮሎኒል_አወል_አብዱሪማን': 1581, 'ሂፓፕ': 1582, 'መሐመድ_አሚን': 1583, 'ብላክ_ኤንጅልስ_ፊልም_ፕሮዳክሽን': 1584, 'አዳ_ወረዳ': 1585, 'ሰራዊት_መልቲሚዲያ_ፕሮዳክሽን': 1586, 'አዋሽ_ብሄራዊ_ፓርክ': 1587, 'ያምሮት_ንጉሴ': 1588, 'ያሬድ_ሹመቴ': 1589, 'ኤችኤም_ፊልም_ፕሮዳክሽን': 1590, 'ሃምራዊ_ፊልም_ፕሮዳክሽን': 1591, 'ማያ_ፊልም_ፕሮዳክሽን': 1592, 'ወንበራ': 1593, 'ሄኖክ_አየለ': 1594, 'አርኪስራ_ፕሮሞሽን': 1595, 'መንቆረር_ፊልም_ፕሮዳክሽን': 1596, 'ኦፔራ': 1597, '2012': 1598, 'ነጎድጓድ_ፊልም_ፕሮዳክሽን': 1599, 'አይዳ_አሸናፊ': 1600, 'ሳይኮሎጅ': 1601, 'ፋሲል_ከነማ_እግርኳስ_ክለብ': 1602, 'ጎዶሊያስ_ኢንተርቴመንት': 1603, 'ሬንደር_ፒክቸር': 1604, 'አብርሃም_ሃይሌ': 1605, 'ኤድሲ_ሚዲያ_ግሩፕ': 1606, 'አክሊሉ_ሀብተወልድ': 1607, 'ክሬቲቭ_ፊልም_ፕሮዳክሽን': 1608, 'አምባሰል_ሙዚቅና_ፊልም_ፕሮዱሰር': 1609, 'ታጠቅ_ፊልም_ፕሮዳክሽን': 1610, 'ባቢሎን_በሳሎን': 1611, 'ቴዲ_ስቱድዮ': 1612, '2006': 1613, 'አሰላ': 1614, 'አክስት': 1615, 'ማሞ_ወልዴ_ስታድየም': 1616, 'ቤዝ_ቤዝ_ጊታር': 1617, 'ኢ_ልብወለድ': 1618, 'አጭር_እርቀት': 1619, 'ደረጃ_2010': 1620, 'ሜራክል_ፊልም_ፕሮዳክሽን': 1621, 'የኛ_ሙዚቃ_ባንድ': 1622, '30000': 1623, 'ዘሌማን_ፕሮዳክሽን': 1624, 'ድሬዳዋ_ከተማ_ፉትቦል_ክለብ': 1625, 'አቢሲኒያ_ፊልም_ፕሮዳክሽን': 1626, 'ጨዋማ_ሀይቅ': 1627, 'ጨጨሆ': 1628, 'ግጥም': 1629, 'ኮራ_ስቱድዮና_ኢንተርቴመንት': 1630, 'ዋልያ_አይቤክስ': 1631, 'ኤሌክትሮኒክስ': 1632, 'ደብረ_ብርሀን': 1633, 'ሀይሌ_ገብረስላሴ_ስታድየም': 1634, '18000': 1635, 'ደደቢት_እግርኳስ_ክለብ_ፉትቦል_ክለብ': 1636, 'የተሰራበት_ሀገር': 1637, 'ሆረር': 1638, 'ሲዳማ_ቡና_ፉትቦል_ክለብ': 1639, 'አውታር_ማተሚያ': 1640, 'ጎል_ጠባቂ': 1641, '10': 1642, 'ባሳካ_ሀይቅ,': 1643, 'አንበሳ_ሙዚቃ_ማተሚያ': 1644, 'ትግረኛ': 1645, 'ድሬዳዋ_ከተማ_እግርኳስ_ክለብ': 1646, 'ሐረሪ_ክልል': 1647, 'ሳላዲን_ሰይድ': 1648, 'መቐለ_ከነማ_ፉትቦል_ክለብ': 1649, 'የተሰለፈው_ብዛት': 1650, '25000': 1651, 'ሲነርጂ_ሃበሻ_ፊልም_ፕሮዳክሽን': 1652, 'ተስፋየ_ማሞ_ፊልም_ፕሮዳክሽን': 1653, 'ማጎ_ምድር_ስእል': 1654, 'ዮሀንስ_ሳህለ': 1655, 'ሲዳማ_ክልል': 1656, 'መቐለ': 1657, 'ላሊበላ_ወረዳ_ምድር_ስእል': 1658, 'ቅዱስ_ጊዮርጊስ_ፉትቦል_ክለብ': 1659, 'አፍሬራ_ሀይቅ,': 1660, '1968': 1661, 'ናሆም_ሪከርድስ_ማተሚያ': 1662, 'አቤኔዘር_ፕሮሞሽን': 1663, 'ሲዳማ_ምስራቃዊ_ክለብ': 1664, 'ጫሞ_ሀይቅ,': 1665, 'ሳኦል_አድነው': 1666, 'ታምሩ_መልቲሚዲያ_ፕሮዳክሽን': 1667, 'መከላከያ_እግርኳስ_ክለብ': 1668, 'ኢትዮጵያ_ቡና_ፉትቦል_ክለብ': 1669, 'መቅዲ_ፕሮዳክሽን': 1670, 'አፈወርቅ_ተክሌ': 1671, 'ኢትዮጵያ_ቡና_እግርኳስ_ክለብ': 1672, '40000': 1673, 'አበበ_ገላው': 1674, 'ኤርሚያስ_ፊልም_ፕሮዳክሽን': 1675, 'ትሪፕ_ሪከርድስ_ማተሚያ': 1676, 'አልፋ_ፊልም_ፕሮዳክሽን': 1677, 'ባህርዳር_ከነማ_እግርኳስ_ክለብ': 1678, 'ሶፍመር_ዋሻ': 1679, 'ኦዚ_ፊልም_ፕሮዳክሽን': 1680, 'ፖለቲካ': 1681, '60000': 1682, 'ደባርቅ_ምድር_ስእል': 1683, 'ቡዳ_ሙዚቅ_ማተሚያ': 1684, 'ሲዳማ_ቡና_እግርኳስ_ክለብ': 1685, 'ሶዶ_ዞን_ምድር_ስእል': 1686, 'አመሀ_እሸቴ_ረከርድስ_ማተሚያ': 1687, 'ፋሲል_ከነማ_ፉትቦል_ክለብ': 1688, 'ሮማርዮ_ረከርድስ_ማተሚያ': 1689, 'መተሀራ': 1690, 'ኢትዮጵያ_እግርኳስ_ፌዴሬሽን': 1691, 'ሀይቅ_ወሎ': 1692, 'ሌግ': 1693, 'ባህርዳር_ከነማ_ፉትቦል_ክለብ': 1694, 'ሀረሪ': 1695, 'ያስመዘገበችው_ጥሩ_ስአት': 1696, '1958': 1697, 'መቐለ_ከነማ_ገባየ_ክለብ': 1698, 'ፌደራል_መንግስት': 1699, 'ተክሉ_ጥላሁን': 1700, 'ራስዳሽን_ተራራ': 1701, 'ባህርዳር_ከተማ_ክለብ': 1702, 'እስራኤል_ገብሩ': 1703, 'አጺውቹና_ባለቤቶቹ': 1704, 'አባ_ጅፋር': 1705, 'ጂማ': 1706, 'አዳማ_ከነማ_እግርኳስ_ክለብ': 1707, '25155': 1708, 'ደደቢት_እግርኳስ_ክለብ_ገባየ_ክለብ': 1709, 'ኢትዮጵያ_ቡና_ገባየ_ክለብ': 1710, 'ቅርስ_አይነት': 1711, 'ባህላዊ': 1712, 'ዩኒቲ_መጻህፍት_መደብር': 1713, 'ጋምቤላ_ከተማ_ክለብ': 1714, 'ቡና_ገባየና_ባለቤቶቹ': 1715, 'አዳማ_ከነማ_ገባየ_ክለብ': 1716, 'ሶማሌ': 1717, 'አዊ_ዞን': 1718, 'ዝዮን_መጻህፍት_መደብር': 1719, 'ትግራይ': 1720, 'አዳማ_ከነማ_ፉትቦል_ክለብ': 1721, 'ምሳሌ_ፊልም_ፕሮዳክሽን': 1722, 'ጅማ_አባ_ጅፋር_ፉትቦል_ክለብ': 1723, '1967': 1724, 'ባህርዳር': 1725, 'የቅጣት_ማእበል': 1726, 'ድላ_ከተማ_ክለብ': 1727, 'ሣልሳዊ_ዳዊት': 1728, 'አዳማ_ከነማና_ባለቤቶቹ': 1729, 'ድሬዳዋ': 1730, '1966': 1731, 'ሰሜን_ተራራ': 1732, '1969': 1733, '1997': 1734, 'ኦሮሚያ': 1735, 'ጣና_ሀይቅ,': 1736, 'የተመሰረተበት_ቀን': 1737, 'ሲዳማ_አጺውቹ': 1738, 'አዳማ_ከተማ_ክለብ': 1739, '1963': 1740, 'ማንጎ_ፒክቸር': 1741, 'ጎንደር_ከተማ_ክለብ': 1742, 'ኮሜርስ_መጻህፍት_መደብር': 1743, 'ታምሶል_ኮምኒኬሽን': 1744, 'ዘንገና_ሀይቅ,': 1745, 'ዝዋይ_ሀይቅ': 1746, 'ድሬዳዋ_ከተማ_ገባየ_ክለብ': 1747, 'መከላከያ_ፉትቦል_ክለብ': 1748, '1993': 1749, 'ፍልስፍና': 1750, 'ኢትዮጵያ_ሙዚቅ': 1751, 'ማጎ_ስምጥ_ሸለቆ': 1752, 'አባይ_ሀይቅ,': 1753, 'መቐለ_ከነማ_እግርኳስ_ክለብ': 1754, 'ዳግማዊት_በቀለ': 1755, 'ሀይቅ_እስጢፋኖስ,': 1756, 'አይናለም_መጻህፍት_መደብር': 1757, 'ዘውግ_ሚድያ_ፕሮሞሽን': 1758, 'ፈረሰኞቹ': 1759, '1973': 1760, 'ደደቢት_እግርኳስ_ክለብ_እግርኳስ_ክለብ': 1761, 'ዘውዱ_መጻህፍት_መደብር': 1762, 'ይርጋለም': 1763, 'ደቡብ_ኢትዮጵያ_ክልል': 1764, 'ሀዋሳ_ከተማ_ገባየ_ክለብ': 1765, 'ከባህር_የወጣ_ዓሣ': 1766, 'ፊፋ_ደረጃ': 1767, 'ጋምቤላ': 1768, 'የደም_ድምጽ': 1769, 'አጺውቹ': 1770, 'ባህርዳር_ከነማ_ገባየ_ክለብ': 1771, 'እነሆ_መጻህፍት_መደብር': 1772, 'ካሌብ__ሃኒባል': 1773, 'ሳይቋጠር_የተፈታ': 1774, 'አፋር': 1775, 'ብርቱካን_ዋሬ': 1776, ',ባሀላዊ_ሙዚቃ_መሳሪያ': 1777, 'አቪሻይ_መኮነን': 1778, 'ሳንጃው': 1779, 'ከንቲባ': 1780, 'ሀዋሳ_ከተማ_ፉትቦል_ክለብ': 1781, '))': 1782, 'አራዶቹ': 1783}\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "pickle_question = open (\"NMT_Etokenizer.pkl\", \"rb\")\n",
        "Qtoken = pickle.load(pickle_question)\n",
        "Eindex2word=Qtoken[2].index_word\n",
        "\n",
        "pickle_logic = open (\"NMT_Mtokenizer.pkl\", \"rb\")\n",
        "Ltoken = pickle.load(pickle_logic)\n",
        "Mindex2word=Ltoken[2].index_word\n",
        "\n",
        "Mword2index=Ltoken[2].word_index\n",
        "\n",
        "#Eindex2word = englishTokenizer.index_word\n",
        "#Mindex2word = marathiTokenizer.index_word\n",
        "\n",
        "print(Mword2index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x65HyVlOPMnL"
      },
      "source": [
        "**Some transformation before giving a string to the function:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCmL2vhzPRys"
      },
      "outputs": [],
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if((i!=0 and i!=Mword2index['start']) and i!=Mword2index['end']):\n",
        "        newString=newString+Mindex2word[i]+' '\n",
        "    return newString\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if(i!=0):\n",
        "        newString=newString+Eindex2word[i]+' '\n",
        "    return newString"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAC2yKXiPTyL"
      },
      "source": [
        "Call the necessary functions and let’s test our translation model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGUfq2YKPX4-"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "for i in range(1):  \n",
        "  X_test=['ሰላም ተስፋየ ጨለማ የሚለው ፊልም ላይ ተውኗል']\n",
        "  pickle_question = open (\"NMT_Etokenizer.pkl\", \"rb\")\n",
        "  Qtoken = pickle.load(pickle_question)\n",
        "  X_test = Qtoken[2].texts_to_sequences(X_test)\n",
        "  X_test = pad_sequences(X_test, maxlen = 14, padding='post')\n",
        "\n",
        "  print(\"Review:\",X_test[0])\n",
        "\n",
        "  #pickle_off = open (\"NMT_data.pkl\", \"rb\")\n",
        "  #emp = pickle.load(pickle_off)\n",
        "  #print(emp[2][0])\n",
        "\n",
        "  #print(\"Review:\",X_test)\n",
        "  print(\"Review:\",seq2text(X_test[0]))\n",
        "\n",
        "  #print(\"Review:\",seq2text(emp[2][0]))\n",
        "  #print(X_test[i].shape)\n",
        "  #print(emp[3][0])\n",
        "  #print(\"Original summary:\",seq2summary(emp[3][0]))\n",
        "\n",
        "  print(\"Predicted summary:\",decode_sequence(X_test[0].reshape(1,14)))\n",
        "  #print(\"Predicted summary:\",decode_sequence(np.pad(X_test[0], (0, 18), 'constant').reshape(1,32)))\n",
        "\n",
        "  #print(\"Predicted summary:\",decode_sequence(emp[2][0].reshape(1,14)))\n",
        "  #print(\"Predicted summary:\",decode_sequence(np.pad(emp[2][0], (0, 18), 'constant').reshape(1,32)))\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluating the model using Bleu and hlepor scores **"
      ],
      "metadata": {
        "id": "wfUCBmsXEMpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hLepor\n",
        "!pip install nptyping"
      ],
      "metadata": {
        "id": "uBDn65E7EGNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from hlepor import single_hlepor_score\n",
        "from hlepor import hlepor_score"
      ],
      "metadata": {
        "id": "Bd0j_UaVEHIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation using Bleu score\n",
        "import re\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "\n",
        "with open('../input/balancedtest/balancedTestdata','r') as f:\n",
        "  data = f.read()\n",
        "testData = data.split('\\n')\n",
        "\n",
        "actual, predicted = list(), list()\n",
        "reference, hypothesis = list(), list()\n",
        "chencherry = SmoothingFunction()\n",
        "\n",
        "sum1=0.0\n",
        "sum2=0.0\n",
        "sum3=0.0\n",
        "sum4=0.0\n",
        "cou=0\n",
        "\n",
        "for word in testData:\n",
        "    cou=cou+1\n",
        "    print(cou)\n",
        "    \n",
        "    X_test=[word.split('\\t')[0]]\n",
        "    #print(X_test)\n",
        "    pickle_question = open (\"../input/semanticmodel/NMT_Etokenizer.pkl\", \"rb\")\n",
        "    Qtoken = pickle.load(pickle_question)\n",
        "    X_test = Qtoken[2].texts_to_sequences(X_test)\n",
        "    X_test = pad_sequences(X_test, maxlen = 14, padding='post')\n",
        "    \n",
        "    #print(word.split('\\t')[1])\n",
        "    #print(decode_sequence(X_test[0].reshape(1,14)))\n",
        "    \n",
        "    #print('BLEU-1: %f' % sentence_bleu([word.split('\\t')[1].split()], decode_sequence(X_test[0].reshape(1,14)).split(), weights=(1.0, 0, 0, 0)))\n",
        "    #print('BLEU-2: %f' % sentence_bleu([word.split('\\t')[1].split()], decode_sequence(X_test[0].reshape(1,14)).split(), weights=(0.5, 0.5, 0, 0)))\n",
        "    #print('BLEU-3: %f' % sentence_bleu([word.split('\\t')[1].split()], decode_sequence(X_test[0].reshape(1,14)).split(), weights=(0.3, 0.3, 0.3, 0)))\n",
        "    #print('BLEU-4: %f' % sentence_bleu([word.split('\\t')[1].split()], decode_sequence(X_test[0].reshape(1,14)).split(), weights=(0.25, 0.25, 0.25, 0.25)))\n",
        "    \n",
        "    #calculating sum...\n",
        "    sum1=sum1+(sentence_bleu([word.split('\\t')[1].split()], decode_sequence(X_test[0].reshape(1,14)).split(), weights=(1.0, 0, 0, 0)))\n",
        "    sum2=sum2+(sentence_bleu([word.split('\\t')[1].split()], decode_sequence(X_test[0].reshape(1,14)).split(), weights=(0.5, 0.5, 0, 0)))\n",
        "    sum3=sum3+(sentence_bleu([word.split('\\t')[1].split()], decode_sequence(X_test[0].reshape(1,14)).split(), weights=(0.3, 0.3, 0.3, 0)))\n",
        "    sum4=sum4+(sentence_bleu([word.split('\\t')[1].split()], decode_sequence(X_test[0].reshape(1,14)).split(), weights=(0.25, 0.25, 0.25, 0.25)))\n",
        "    \n",
        "\n",
        "    #actual logic form\n",
        "    #actual.append(word.split('\\t')[1].split())\n",
        "    #predicted logic form\n",
        "    #predicted.append(decode_sequence(X_test[0].reshape(1,14)).split())\n",
        "    \n",
        "    #calculating sentence level LEPOR...\n",
        "    #hLepor_value = single_hlepor_score(word.split('\\t')[1], decode_sequence(X_test[0].reshape(1,14)))\n",
        "    #print(round(hLepor_value, 4))\n",
        "    \n",
        "    #reference.append(word.split('\\t')[1])  \n",
        "    #hypothesis.append(decode_sequence(X_test[0].reshape(1,14)))\n",
        "#print(\"average scores of sentence level BLEU scores...\")\n",
        "print(sum1/686)\n",
        "print(sum2/686)\n",
        "print(sum3/686)\n",
        "print(sum4/686)\n",
        "#bleu scores\n",
        "#print(\"calculating bleu scores...\")    \n",
        "#print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
        "#print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
        "#print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
        "#print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25))) \n",
        "\n",
        "#calculating LEPOR (Length Penalty, Precision, n-gram Position difference Penalty and Recall)...\n",
        "#hLepor_value = hlepor_score(reference, hypothesis)\n",
        "#round(hLepor_value, 4)"
      ],
      "metadata": {
        "id": "YRYA1so7E2qz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}